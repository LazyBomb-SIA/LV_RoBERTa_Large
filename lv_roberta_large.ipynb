{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e014f1",
   "metadata": {},
   "source": [
    "### Please download the model from Hugging Face\n",
    "\n",
    "### Hugging Face Model Repo:\n",
    "https://huggingface.co/JesseHuang922/lv_roberta_large\n",
    "\n",
    "Due to GitHub's file size limit (maximum 100MB per file), the larger RoBERTa-based models are not included in this repository.\n",
    "\n",
    "Specifically, files under ./models/* and ./packages/* are excluded from version control.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "731f7d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports and directories are created\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Cell 0：Import and directories\n",
    "# ==============================\n",
    "from pathlib import Path\n",
    "import os\n",
    "import spacy\n",
    "from spacy.lookups import Lookups\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.cli.package import package\n",
    "\n",
    "# Project root dir\n",
    "project_root = Path(\".\").resolve()\n",
    "\n",
    "# Project structure\n",
    "corpus_dir = project_root / \"corpus\"\n",
    "models_dir = project_root / \"models\"\n",
    "model_name = \"lv_roberta_large\"\n",
    "trained_model_path = models_dir / model_name / \"model-best\"\n",
    "final_model_path = models_dir / model_name / \"model_roberta_large\"\n",
    "lookups_path = project_root / \"lookups_lv\"\n",
    "package_output_dir = project_root / \"packages\"\n",
    "config_path = project_root / \"config\" / \"config_roberta_large.cfg\"\n",
    "\n",
    "# Create directories\n",
    "for p in [corpus_dir, models_dir, models_dir / model_name, package_output_dir, lookups_path, project_root / \"config\"]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Imports and directories are created\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f52f505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
      "\u001b[38;5;2m✔ Generated output file (1506 documents):\n",
      "corpus/lv_lvtb-ud-train.spacy\u001b[0m\n",
      "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
      "\u001b[38;5;2m✔ Generated output file (208 documents):\n",
      "corpus/lv_lvtb-ud-dev.spacy\u001b[0m\n",
      "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
      "\u001b[38;5;2m✔ Generated output file (240 documents):\n",
      "corpus/lv_lvtb-ud-test.spacy\u001b[0m\n",
      "\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n",
      "\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n",
      "into documents with `-n 10`.\u001b[0m\n",
      "\u001b[38;5;2m✔ Generated output file (2396 documents):\n",
      "test/lv_lvtb-ud-test.spacy\u001b[0m\n",
      "All conllu files are converted to spaCy Format.\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# Cell 1：Convert conllu to spaCy format\n",
    "# ======================================\n",
    "!python -m spacy convert ud_latvian/lv_lvtb-ud-train.conllu ./corpus -n 10\n",
    "!python -m spacy convert ud_latvian/lv_lvtb-ud-dev.conllu ./corpus -n 10\n",
    "!python -m spacy convert ud_latvian/lv_lvtb-ud-test.conllu ./corpus -n 10\n",
    "\n",
    "# For testing\n",
    "!python -m spacy convert ud_latvian/lv_lvtb-ud-test.conllu ./test\n",
    "\"\"\"\n",
    "Using a lookup table for lemmatization matches words solely based on their surface form (or lowercase),\n",
    "without considering context. In longer documents (multiple sentences or complex structures):\n",
    "\n",
    "    - spaCy's lemmatization may be indirectly affected by pipeline processing and Vocab caching. \n",
    "      For example, repeated tokens or subtle variations in capitalization/punctuation can lead \n",
    "      to lookup misses.\n",
    "    - Some compound or modified words might not exist in the lookup table.\n",
    "\n",
    "As a result, longer documents increase the likelihood of lookup failures, reducing overall lemma accuracy.\n",
    "\n",
    "To balance this, during training we group 10 sentences per Doc to provide richer context for\n",
    "sentence segmentation learning. For evaluating lemma performance, however, we use a test set\n",
    "with one sentence per Doc, which isolates lemma accuracy from potential inter-sentence effects.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"All conllu files are converted to spaCy Format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a06f6699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: lv\n",
      "- Pipeline: tagger, morphologizer, parser, senter\n",
      "- Optimize for: efficiency\n",
      "- Hardware: GPU\n",
      "- Transformer: bert-base-multilingual-uncased\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config/config_roberta_large.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_roberta_large.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# Cell 2：Initializing config\n",
    "# =============================\n",
    "!python -m spacy init config ./config/config_roberta_large.cfg \\\n",
    "    --lang lv \\\n",
    "    --pipeline transformer,tagger,morphologizer,parser,senter \\\n",
    "    --optimize efficiency \\\n",
    "    --gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "042c3863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config updated: training/calidation set path, transformer base model, mixed precision and pipeline + trf_tok2vec components are all set\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Cell 3：Modify config\n",
    "# ==========================\n",
    "\n",
    "# Read config file\n",
    "cfg_text = config_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# Replace the training/validation set path\n",
    "cfg_text = cfg_text.replace(\"train = null\", f\"train = {corpus_dir}/lv_lvtb-ud-train.spacy\")\n",
    "cfg_text = cfg_text.replace(\"dev = null\", f\"dev = {corpus_dir}/lv_lvtb-ud-dev.spacy\")\n",
    "\n",
    "# Change transformer model to xlm-roberta-large\n",
    "cfg_text = cfg_text.replace(\"bert-base-multilingual-uncased\", \"xlm-roberta-large\")\n",
    "\n",
    "# Turn on Mixed Precision\n",
    "cfg_text = cfg_text.replace(\"mixed_precision = false\", \"mixed_precision = true\")\n",
    "\n",
    "# Modify pipeline： add trf_tok2vec component to pipeline\n",
    "cfg_text = cfg_text.replace(\n",
    "    'pipeline = [\"transformer\",\"tagger\",\"morphologizer\",\"parser\",\"senter\"]',\n",
    "    'pipeline = [\"transformer\",\"trf_tok2vec\",\"tagger\",\"morphologizer\",\"parser\",\"senter\"]'\n",
    ")\n",
    "\n",
    "# Add trf_tok2vec component config\n",
    "if \"[components.trf_tok2vec]\" not in cfg_text:\n",
    "    trf_tok2vec_cfg = \"\"\"\n",
    "[components.trf_tok2vec]\n",
    "factory = \"tok2vec\"\n",
    "\n",
    "[components.trf_tok2vec.model]\n",
    "@architectures = \"spacy-transformers.TransformerListener.v1\"\n",
    "grad_factor = 1.0\n",
    "pooling = {\"@layers\":\"reduce_mean.v1\"}\n",
    "upstream = \"*\"\n",
    "\"\"\"\n",
    "    cfg_text += trf_tok2vec_cfg\n",
    "\n",
    "config_path.write_text(cfg_text, encoding=\"utf-8\")\n",
    "print(\"Config updated: training/calidation set path, transformer base model, mixed precision and pipeline + trf_tok2vec components are all set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcf4dc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Lemma lookup table generated, mode: ['lv_lvtb-ud-train.spacy', 'lv_lvtb-ud-dev.spacy', 'lv_lvtb-ud-test.spacy'], saved at: lookups_lv\n"
     ]
    }
   ],
   "source": [
    "# ===================================\n",
    "# Cell 4：Generate lemma lookup table\n",
    "# ===================================\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.lookups import Lookups\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "corpus_dir = Path(\"corpus\")\n",
    "lookups_path = Path(\"lookups_lv\")\n",
    "\n",
    "# --------------- Choose generation mode ---------------\n",
    "# Mode 1: Strict evaluation mode (train + dev only)\n",
    "# files = [\"lv_lvtb-ud-train.spacy\", \"lv_lvtb-ud-dev.spacy\"]\n",
    "\n",
    "# Mode 2: Practical enhanced mode (train + dev + test)\n",
    "files = [\"lv_lvtb-ud-train.spacy\", \"lv_lvtb-ud-dev.spacy\", \"lv_lvtb-ud-test.spacy\"] # more is always better, though here the return is mininal.\n",
    "\n",
    "# --------------- Generate lemma lookup ---------------\n",
    "lemma_dict = {}\n",
    "nlp_blank = spacy.blank(\"lv\")\n",
    "\n",
    "for file_name in files:\n",
    "    docbin = DocBin().from_disk(corpus_dir / file_name)\n",
    "    for doc in docbin.get_docs(nlp_blank.vocab):\n",
    "        for token in doc:\n",
    "            if token.lemma_:\n",
    "                lemma_dict[token.text.lower()] = token.lemma_\n",
    "\n",
    "lookups = Lookups()\n",
    "lookups.add_table(\"lemma_lookup\", lemma_dict)\n",
    "lookups.to_disk(lookups_path)\n",
    "\n",
    "print(f\"✅ Lemma lookup table generated, mode: {files}, saved at: {lookups_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29989503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: models/lv_roberta_large\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['transformer', 'trf_tok2vec', 'tagger', 'morphologizer',\n",
      "'parser', 'senter']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS TRF_T...  LOSS TAGGER  LOSS MORPH...  LOSS PARSER  LOSS SENTER  TAG_ACC  POS_ACC  MORPH_ACC  DEP_UAS  DEP_LAS  SENTS_P  SENTS_R  SENTS_F  SCORE \n",
      "---  ------  -------------  -------------  -----------  -------------  -----------  -----------  -------  -------  ---------  -------  -------  -------  -------  -------  ------\n",
      "  0       0        8030.10           0.00      1300.29        1299.83      1752.90       652.50     0.00     3.90       2.73    31.19     0.01     0.00     0.00     0.00    0.05\n",
      "  1     200      480831.81           0.00    355246.75      352773.92    369174.87    176225.87    27.32    61.68      44.97    73.81    59.55    56.10    70.29    62.40    0.52\n",
      "  2     400      135185.43           0.00    233465.58      176298.96    148354.24    140965.42    74.54    96.67      89.67    87.92    82.90    91.39    92.93    92.16    0.86\n",
      "  4     600       81747.72           0.00     98347.63       41764.65     85530.46     81683.94    86.59    98.14      95.07    91.03    87.44    96.79    97.12    96.95    0.92\n",
      "  5     800       60616.01           0.00     52754.78       22695.07     63642.44     43614.27    90.92    98.42      96.34    91.85    88.45    96.88    96.97    96.92    0.94\n",
      "  7    1000       50695.20           0.00     36098.18       15959.31     54098.98     24966.35    92.11    98.46      96.41    92.26    88.87    97.87    97.07    97.47    0.94\n",
      "  8    1200       41751.15           0.00     27869.41       12264.44     45687.50     15683.19    92.77    98.53      96.56    92.23    88.97    97.93    97.69    97.81    0.95\n",
      "  9    1400       37294.71           0.00     23050.27       10119.96     41265.61     10855.57    93.03    98.54      96.60    92.56    89.41    98.36    98.12    98.24    0.95\n",
      " 11    1600       31007.11           0.00     19311.29        8298.60     36191.04      8435.72    93.17    98.58      96.62    92.20    89.06    98.40    97.69    98.05    0.95\n",
      " 12    1800       28339.14           0.00     16749.33        7109.98     33883.18      6862.07    93.39    98.56      96.83    92.43    89.33    98.17    98.12    98.15    0.95\n",
      " 14    2000       24063.76           0.00     14209.23        5939.61     30426.03      5574.98    93.44    98.56      96.77    92.49    89.28    98.22    98.17    98.20    0.95\n",
      " 15    2200       19749.46           0.00     12187.09        4848.45     27781.21      5063.90    93.62    98.59      96.74    92.58    89.47    98.22    98.17    98.20    0.95\n",
      " 16    2400       18360.49           0.00     10629.04        4250.78     26008.41      4227.42    93.67    98.59      96.82    92.63    89.51    98.22    97.93    98.07    0.95\n",
      " 18    2600       16096.49           0.00      8959.02        3489.43     24548.12      3883.17    93.67    98.63      96.90    92.57    89.48    97.55    97.64    97.60    0.95\n",
      " 19    2800       13942.66           0.00      7957.14        3120.94     22858.92      3568.01    93.69    98.60      96.77    92.77    89.51    97.51    97.88    97.70    0.95\n",
      " 21    3000       12088.27           0.00      6701.53        2556.73     21553.60      3343.58    93.62    98.59      96.86    92.67    89.64    98.75    98.56    98.65    0.95\n",
      " 22    3200       10596.25           0.00      5869.88        2212.22     20752.46      3237.04    93.79    98.62      96.80    92.63    89.54    98.65    98.51    98.58    0.95\n",
      " 23    3400       10327.40           0.00      5120.13        1856.22     20033.49      3143.98    93.79    98.57      96.85    92.60    89.38    97.26    97.36    97.31    0.95\n",
      " 25    3600        9088.65           0.00      4841.54        1652.06     19625.13      2911.89    93.75    98.56      96.87    92.75    89.57    98.41    98.22    98.32    0.95\n",
      " 26    3800        8217.89           0.00      4597.55        1545.72     19044.74      2916.18    93.85    98.54      96.91    92.64    89.49    98.03    97.98    98.00    0.95\n",
      " 28    4000        7481.04           0.00      4033.19        1355.14     19147.24      2851.41    93.79    98.56      96.84    92.75    89.63    98.70    98.41    98.56    0.95\n",
      " 29    4200        6864.11           0.00      3455.19        1255.25     18418.05      2849.32    93.71    98.51      96.78    92.73    89.62    98.55    98.22    98.39    0.95\n",
      " 30    4400        6716.26           0.00      3292.99        1221.09     18622.68      2675.44    93.74    98.56      96.78    92.92    89.86    98.84    98.22    98.53    0.95\n",
      " 32    4600        5827.72           0.00      2967.51        1068.67     18081.01      2656.07    93.86    98.57      96.87    92.58    89.52    98.75    98.41    98.58    0.95\n",
      " 33    4800        5625.97           0.00      2903.44         976.98     18068.87      2606.39    93.76    98.58      96.83    92.70    89.69    98.79    97.98    98.38    0.95\n",
      " 35    5000        6176.82           0.00      2835.13        1049.67     18250.29      2690.59    93.75    98.51      96.82    92.56    89.40    98.94    98.37    98.65    0.95\n",
      " 36    5200        6010.43           0.00      2804.38        1005.98     17847.60      2499.64    93.75    98.56      96.83    92.58    89.50    98.56    98.41    98.48    0.95\n",
      " 37    5400        6060.19           0.00      2658.96         888.73     18095.18      2575.06    93.79    98.57      96.81    92.84    89.69    98.55    97.98    98.26    0.95\n",
      " 39    5600        6234.46           0.00      2581.25         868.27     18204.90      2539.15    93.74    98.54      96.80    92.57    89.49    97.88    97.74    97.81    0.95\n",
      " 40    5800        5667.02           0.00      2667.96         951.05     17832.45      2492.63    93.77    98.50      96.79    92.61    89.49    98.36    97.98    98.17    0.95\n",
      " 42    6000        4851.99           0.00      2637.07         937.40     17366.65      2485.12    93.72    98.56      96.81    92.74    89.57    98.94    98.37    98.65    0.95\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "models/lv_roberta_large/model-last\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Cell 5：Train RoBERTa large model\n",
    "# ================================\n",
    "!python -m spacy train ./config/config_roberta_large.cfg \\\n",
    "    --output ./models/lv_roberta_large\\\n",
    "    --paths.train ./corpus/lv_lvtb-ud-train.spacy \\\n",
    "    --paths.dev ./corpus/lv_lvtb-ud-dev.spacy \\\n",
    "    --gpu-id 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef8e6f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK      99.53\n",
      "TAG      93.40\n",
      "POS      98.20\n",
      "MORPH    96.31\n",
      "UAS      92.71\n",
      "LAS      89.53\n",
      "SENT P   98.21\n",
      "SENT R   98.21\n",
      "SENT F   98.21\n",
      "SPEED    13367\n",
      "\n",
      "\u001b[1m\n",
      "============================== MORPH (per feat) ==============================\u001b[0m\n",
      "\n",
      "               P        R       F\n",
      "ExtPos     92.59    89.93   91.24\n",
      "Case       98.42    97.66   98.04\n",
      "Gender     97.84    96.95   97.39\n",
      "Number     98.40    97.57   97.98\n",
      "Person     98.93    98.82   98.88\n",
      "PronType   98.71    98.31   98.51\n",
      "Evident    99.06    99.17   99.11\n",
      "Mood       98.69    98.62   98.66\n",
      "Polarity   99.49    99.53   99.51\n",
      "Tense      97.70    97.91   97.81\n",
      "VerbForm   99.18    99.22   99.20\n",
      "Voice      99.36    99.40   99.38\n",
      "Definite   98.18    98.08   98.13\n",
      "Degree     99.16    98.89   99.02\n",
      "Poss       99.46   100.00   99.73\n",
      "NumType    99.61    76.91   86.80\n",
      "Reflex     99.46    99.46   99.46\n",
      "Aspect     98.59    98.98   98.79\n",
      "Foreign    96.27    81.58   88.32\n",
      "Typo       25.00     1.92    3.57\n",
      "Abbr       94.79    83.11   88.56\n",
      "\n",
      "\u001b[1m\n",
      "=============================== LAS (per type) ===============================\u001b[0m\n",
      "\n",
      "                    P        R        F\n",
      "mark            95.05    96.31    95.67\n",
      "fixed           91.10    95.68    93.33\n",
      "nsubj           94.78    94.78    94.78\n",
      "discourse       80.48    73.38    76.77\n",
      "advcl           79.15    77.10    78.11\n",
      "amod            95.76    90.26    92.93\n",
      "obj             94.68    95.54    95.11\n",
      "cc              95.81    95.94    95.87\n",
      "det             93.39    93.29    93.34\n",
      "conj            85.55    86.23    85.89\n",
      "xcomp           92.19    90.08    91.12\n",
      "aux             97.18    95.63    96.40\n",
      "root            95.36    95.16    95.26\n",
      "nmod            91.35    90.75    91.05\n",
      "ccomp           87.97    88.40    88.18\n",
      "nummod          93.64    93.31    93.47\n",
      "case            97.97    96.81    97.39\n",
      "iobj            76.70    77.66    77.18\n",
      "advmod          90.17    90.60    90.38\n",
      "obl             86.61    80.95    83.69\n",
      "advmod:emph     78.82    81.95    80.35\n",
      "cop             91.11    88.42    89.74\n",
      "aux:pass        92.99    92.99    92.99\n",
      "acl             84.96    81.74    83.32\n",
      "nsubj:pass      90.67    95.67    93.10\n",
      "advmod:neg      70.00    84.00    76.36\n",
      "parataxis       69.37    69.37    69.37\n",
      "appos           76.27    67.16    71.43\n",
      "dep             12.39    15.05    13.59\n",
      "csubj           81.63    78.43    80.00\n",
      "flat            76.32    70.73    73.42\n",
      "flat:foreign    14.29     8.33    10.53\n",
      "flat:name       93.44    82.60    87.68\n",
      "csubj:pass      53.85    58.33    56.00\n",
      "vocative        84.00    72.41    77.78\n",
      "orphan          56.94    41.00    47.67\n",
      "reparandum       0.00     0.00     0.00\n",
      "compound       100.00   100.00   100.00\n",
      "goeswith         0.00     0.00     0.00\n",
      "dislocated       0.00     0.00     0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Cell 6: Evaluation\n",
    "# ========================\n",
    "!python -m spacy evaluate ./models/lv_roberta_large//model-best ./corpus/lv_lvtb-ud-test.spacy --gpu-id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae0d87ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: models/lv_roberta_large/model_roberta_large, with lemmatizer + lookups\n",
      "LICENSE copied to: models/lv_roberta_large/model_roberta_large/LICENSE\n",
      "LICENSES_SOURCES copied to: models/lv_roberta_large/model_roberta_large/LICENSES_SOURCES\n",
      "README.md copied to: models/lv_roberta_large/model_roberta_large/README.md\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================\n",
    "# Cell 7：Add Lemmatizer (lookup) to model + Copy LICENSE, LICENSE_SOURCES & README\n",
    "# =================================================================================\n",
    "import spacy\n",
    "from spacy.lookups import Lookups\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "trained_model_path = \"./models/lv_roberta_large/model-best\"\n",
    "final_model_path = Path(\"./models/lv_roberta_large/model_roberta_large\")\n",
    "lookups_path = \"./lookups_lv\"\n",
    "\n",
    "# Load trained model\n",
    "nlp = spacy.load(trained_model_path)\n",
    "\n",
    "# Add lookups\n",
    "lookups = Lookups().from_disk(lookups_path)\n",
    "\n",
    "# Add lemmatizer to pipeline\n",
    "lemmatizer = nlp.add_pipe(\"lemmatizer\", config={\"mode\": \"lookup\"}, last=True)\n",
    "lemmatizer.lookups = lookups  # assign properties directly here\n",
    "\n",
    "# Save new model with lemmatizer components\n",
    "nlp.to_disk(final_model_path)\n",
    "print(f\"Model saved to: {final_model_path}, with lemmatizer + lookups\")\n",
    "\n",
    "# Copy LICENSE.txt into the final model path, rename to LICENSE\n",
    "license_src = Path(\"./LICENSE.txt\")   # 项目根目录下的 LICENSE.txt\n",
    "license_dst = final_model_path / \"LICENSE\"  # 注意：没有后缀\n",
    "if license_src.exists():\n",
    "    shutil.copy(license_src, license_dst)\n",
    "    print(f\"LICENSE copied to: {license_dst}\")\n",
    "else:\n",
    "    print(\"⚠️ WARNING: LICENSE.txt not found in project root!\")\n",
    "\n",
    "# Copy LICENSES_SOURCES.txt into the final model path, rename to LICENSES_SOURCES\n",
    "licenses_sources_src = Path(\"./LICENSES_SOURCES.txt\")\n",
    "licenses_sources_dst = final_model_path / \"LICENSES_SOURCES\"\n",
    "if licenses_sources_src.exists():\n",
    "    shutil.copy(licenses_sources_src, licenses_sources_dst)\n",
    "    print(f\"LICENSES_SOURCES copied to: {licenses_sources_dst}\")\n",
    "else:\n",
    "    print(\"⚠️ WARNING: LICENSES_SOURCES.txt not found in project root!\")\n",
    "\n",
    "# Copy README.md into the final model path\n",
    "readme_src = Path(\"./README.md\")\n",
    "readme_dst = final_model_path / \"README.md\"\n",
    "if readme_src.exists():\n",
    "    shutil.copy(readme_src, readme_dst)\n",
    "    print(f\"README.md copied to: {readme_dst}\")\n",
    "else:\n",
    "    print(\"⚠️ WARNING: README.md not found in project root!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38e816ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m* Creating isolated environment: venv+pip...\u001b[0m\n",
      "\u001b[1m* Installing packages in isolated environment:\u001b[0m\n",
      "  - setuptools >= 40.8.0\n",
      "\u001b[1m* Getting build dependencies for sdist...\u001b[0m\n",
      "running egg_info\n",
      "creating lv_roberta_large.egg-info\n",
      "writing lv_roberta_large.egg-info/PKG-INFO\n",
      "writing dependency_links to lv_roberta_large.egg-info/dependency_links.txt\n",
      "writing entry points to lv_roberta_large.egg-info/entry_points.txt\n",
      "writing requirements to lv_roberta_large.egg-info/requires.txt\n",
      "writing top-level names to lv_roberta_large.egg-info/top_level.txt\n",
      "writing manifest file 'lv_roberta_large.egg-info/SOURCES.txt'\n",
      "reading manifest file 'lv_roberta_large.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "adding license file 'LICENSE'\n",
      "adding license file 'LICENSES_SOURCES'\n",
      "writing manifest file 'lv_roberta_large.egg-info/SOURCES.txt'\n",
      "\u001b[1m* Building sdist...\u001b[0m\n",
      "running sdist\n",
      "running egg_info\n",
      "writing lv_roberta_large.egg-info/PKG-INFO\n",
      "writing dependency_links to lv_roberta_large.egg-info/dependency_links.txt\n",
      "writing entry points to lv_roberta_large.egg-info/entry_points.txt\n",
      "writing requirements to lv_roberta_large.egg-info/requires.txt\n",
      "writing top-level names to lv_roberta_large.egg-info/top_level.txt\n",
      "reading manifest file 'lv_roberta_large.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "adding license file 'LICENSE'\n",
      "adding license file 'LICENSES_SOURCES'\n",
      "writing manifest file 'lv_roberta_large.egg-info/SOURCES.txt'\n",
      "running check\n",
      "creating lv_roberta_large-1.0.0\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large.egg-info\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/lemmatizer/lookups\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/morphologizer\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/parser\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/senter\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/tagger\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/transformer\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying files to lv_roberta_large-1.0.0...\n",
      "copying LICENSE -> lv_roberta_large-1.0.0\n",
      "copying LICENSES_SOURCES -> lv_roberta_large-1.0.0\n",
      "copying MANIFEST.in -> lv_roberta_large-1.0.0\n",
      "copying README.md -> lv_roberta_large-1.0.0\n",
      "copying meta.json -> lv_roberta_large-1.0.0\n",
      "copying setup.py -> lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/__init__.py -> lv_roberta_large-1.0.0/lv_roberta_large\n",
      "copying lv_roberta_large/meta.json -> lv_roberta_large-1.0.0/lv_roberta_large\n",
      "copying lv_roberta_large.egg-info/PKG-INFO -> lv_roberta_large-1.0.0/lv_roberta_large.egg-info\n",
      "copying lv_roberta_large.egg-info/SOURCES.txt -> lv_roberta_large-1.0.0/lv_roberta_large.egg-info\n",
      "copying lv_roberta_large.egg-info/dependency_links.txt -> lv_roberta_large-1.0.0/lv_roberta_large.egg-info\n",
      "copying lv_roberta_large.egg-info/entry_points.txt -> lv_roberta_large-1.0.0/lv_roberta_large.egg-info\n",
      "copying lv_roberta_large.egg-info/not-zip-safe -> lv_roberta_large-1.0.0/lv_roberta_large.egg-info\n",
      "copying lv_roberta_large.egg-info/requires.txt -> lv_roberta_large-1.0.0/lv_roberta_large.egg-info\n",
      "copying lv_roberta_large.egg-info/top_level.txt -> lv_roberta_large-1.0.0/lv_roberta_large.egg-info\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/LICENSE -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/LICENSES_SOURCES -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/README.md -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/config.cfg -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/meta.json -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/tokenizer -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/lemmatizer/lookups/lookups.bin -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/lemmatizer/lookups\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/morphologizer/cfg -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/morphologizer\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/morphologizer/model -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/morphologizer\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/parser/cfg -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/parser\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/parser/model -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/parser\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/parser/moves -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/parser\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/senter/cfg -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/senter\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/senter/model -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/senter\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/tagger/cfg -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/tagger\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/tagger/model -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/tagger\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/transformer/cfg -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/transformer\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/transformer/model -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/transformer\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec/cfg -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec/model -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/vocab/key2row -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/vocab/lookups.bin -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/vocab/strings.json -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/vocab/vectors -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/vocab/vectors.cfg -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying lv_roberta_large.egg-info/SOURCES.txt -> lv_roberta_large-1.0.0/lv_roberta_large.egg-info\n",
      "Writing lv_roberta_large-1.0.0/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'lv_roberta_large-1.0.0' (and everything under it)\n",
      "\u001b[1m\u001b[92mSuccessfully built \u001b[4mlv_roberta_large-1.0.0.tar.gz\u001b[0m\u001b[1m\u001b[92m\u001b[0m\n",
      "Finished, packaged model can be found here: /home/jesse/Projects/myprojs/LV_spaCy_Pipeline/LV_RoBERTa_Large/packages\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# Cell 8：Packaging\n",
    "# =======================\n",
    "\n",
    "from spacy.cli.package import package\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "project_root = Path(\".\").resolve()\n",
    "os.environ[\"PYTHONPATH\"] = f\"{project_root}:{os.environ.get('PYTHONPATH','')}\"\n",
    "\n",
    "# Note that the string path is replaced with a Path object (don't know why but it works only this way)\n",
    "package(\n",
    "    input_dir=Path(final_model_path),\n",
    "    output_dir=Path(package_output_dir),\n",
    "    name=\"roberta_large\",\n",
    "    version=\"1.0.0\",\n",
    "    force=True\n",
    ")\n",
    "\n",
    "print(f\"Finished, packaged model can be found here: {package_output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87665a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m* Creating isolated environment: venv+pip...\u001b[0m\n",
      "\u001b[1m* Installing packages in isolated environment:\u001b[0m\n",
      "  - setuptools >= 40.8.0\n",
      "\u001b[1m* Getting build dependencies for wheel...\u001b[0m\n",
      "running egg_info\n",
      "writing lv_roberta_large.egg-info/PKG-INFO\n",
      "writing dependency_links to lv_roberta_large.egg-info/dependency_links.txt\n",
      "writing entry points to lv_roberta_large.egg-info/entry_points.txt\n",
      "writing requirements to lv_roberta_large.egg-info/requires.txt\n",
      "writing top-level names to lv_roberta_large.egg-info/top_level.txt\n",
      "reading manifest file 'lv_roberta_large.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "adding license file 'LICENSE'\n",
      "adding license file 'LICENSES_SOURCES'\n",
      "writing manifest file 'lv_roberta_large.egg-info/SOURCES.txt'\n",
      "\u001b[1m* Building wheel...\u001b[0m\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build/lib/lv_roberta_large\n",
      "copying lv_roberta_large/__init__.py -> build/lib/lv_roberta_large\n",
      "creating build/lib/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/meta.json -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/LICENSE -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/README.md -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/LICENSES_SOURCES -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/tokenizer -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/config.cfg -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "creating build/lib/lv_roberta_large/lv_roberta_large-1.0.0/morphologizer\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/morphologizer/cfg -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/morphologizer\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/morphologizer/model -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/morphologizer\n",
      "creating build/lib/lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec/cfg -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec/model -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec\n",
      "creating build/lib/lv_roberta_large/lv_roberta_large-1.0.0/transformer\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/transformer/cfg -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/transformer\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/transformer/model -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/transformer\n",
      "creating build/lib/lv_roberta_large/lv_roberta_large-1.0.0/tagger\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/tagger/cfg -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/tagger\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/tagger/model -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/tagger\n",
      "creating build/lib/lv_roberta_large/lv_roberta_large-1.0.0/senter\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/senter/cfg -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/senter\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/senter/model -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/senter\n",
      "creating build/lib/lv_roberta_large/lv_roberta_large-1.0.0/parser\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/parser/cfg -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/parser\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/parser/moves -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/parser\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/parser/model -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/parser\n",
      "creating build/lib/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/vocab/lookups.bin -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/vocab/key2row -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/vocab/vectors -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/vocab/strings.json -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/vocab/vectors.cfg -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "creating build/lib/lv_roberta_large/lv_roberta_large-1.0.0/lemmatizer/lookups\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/lemmatizer/lookups/lookups.bin -> build/lib/lv_roberta_large/lv_roberta_large-1.0.0/lemmatizer/lookups\n",
      "copying lv_roberta_large/meta.json -> build/lib/lv_roberta_large\n",
      "installing to build/bdist.linux-x86_64/wheel\n",
      "running install\n",
      "running install_lib\n",
      "creating build/bdist.linux-x86_64/wheel\n",
      "creating build/bdist.linux-x86_64/wheel/lv_roberta_large\n",
      "copying build/lib/lv_roberta_large/meta.json -> build/bdist.linux-x86_64/wheel/./lv_roberta_large\n",
      "creating build/bdist.linux-x86_64/wheel/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "creating build/bdist.linux-x86_64/wheel/lv_roberta_large/lv_roberta_large-1.0.0/morphologizer\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/morphologizer/cfg -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/morphologizer\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/morphologizer/model -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/morphologizer\n",
      "creating build/bdist.linux-x86_64/wheel/lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec/cfg -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec/model -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec\n",
      "creating build/bdist.linux-x86_64/wheel/lv_roberta_large/lv_roberta_large-1.0.0/transformer\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/transformer/cfg -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/transformer\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/transformer/model -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/transformer\n",
      "creating build/bdist.linux-x86_64/wheel/lv_roberta_large/lv_roberta_large-1.0.0/tagger\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/tagger/cfg -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/tagger\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/tagger/model -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/tagger\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/meta.json -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0\n",
      "creating build/bdist.linux-x86_64/wheel/lv_roberta_large/lv_roberta_large-1.0.0/senter\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/senter/cfg -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/senter\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/senter/model -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/senter\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/LICENSE -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0\n",
      "creating build/bdist.linux-x86_64/wheel/lv_roberta_large/lv_roberta_large-1.0.0/parser\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/parser/cfg -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/parser\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/parser/moves -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/parser\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/parser/model -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/parser\n",
      "creating build/bdist.linux-x86_64/wheel/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/vocab/lookups.bin -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/vocab/key2row -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/vocab/vectors -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/vocab/strings.json -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/vocab/vectors.cfg -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/README.md -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/LICENSES_SOURCES -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/tokenizer -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/config.cfg -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0\n",
      "creating build/bdist.linux-x86_64/wheel/lv_roberta_large/lv_roberta_large-1.0.0/lemmatizer\n",
      "creating build/bdist.linux-x86_64/wheel/lv_roberta_large/lv_roberta_large-1.0.0/lemmatizer/lookups\n",
      "copying build/lib/lv_roberta_large/lv_roberta_large-1.0.0/lemmatizer/lookups/lookups.bin -> build/bdist.linux-x86_64/wheel/./lv_roberta_large/lv_roberta_large-1.0.0/lemmatizer/lookups\n",
      "copying build/lib/lv_roberta_large/__init__.py -> build/bdist.linux-x86_64/wheel/./lv_roberta_large\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "writing lv_roberta_large.egg-info/PKG-INFO\n",
      "writing dependency_links to lv_roberta_large.egg-info/dependency_links.txt\n",
      "writing entry points to lv_roberta_large.egg-info/entry_points.txt\n",
      "writing requirements to lv_roberta_large.egg-info/requires.txt\n",
      "writing top-level names to lv_roberta_large.egg-info/top_level.txt\n",
      "reading manifest file 'lv_roberta_large.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "adding license file 'LICENSE'\n",
      "adding license file 'LICENSES_SOURCES'\n",
      "writing manifest file 'lv_roberta_large.egg-info/SOURCES.txt'\n",
      "Copying lv_roberta_large.egg-info to build/bdist.linux-x86_64/wheel/./lv_roberta_large-1.0.0-py3.12.egg-info\n",
      "running install_scripts\n",
      "creating build/bdist.linux-x86_64/wheel/lv_roberta_large-1.0.0.dist-info/WHEEL\n",
      "creating '/home/jesse/Projects/myprojs/LV_spaCy_Pipeline/LV_RoBERTa_Large/packages/lv_roberta_large-1.0.0/dist/.tmp-e2vztl6q/lv_roberta_large-1.0.0-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
      "adding 'lv_roberta_large/__init__.py'\n",
      "adding 'lv_roberta_large/meta.json'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/LICENSE'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/LICENSES_SOURCES'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/README.md'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/config.cfg'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/meta.json'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/tokenizer'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/lemmatizer/lookups/lookups.bin'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/morphologizer/cfg'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/morphologizer/model'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/parser/cfg'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/parser/model'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/parser/moves'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/senter/cfg'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/senter/model'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/tagger/cfg'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/tagger/model'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/transformer/cfg'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/transformer/model'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec/cfg'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec/model'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/vocab/key2row'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/vocab/lookups.bin'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/vocab/strings.json'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/vocab/vectors'\n",
      "adding 'lv_roberta_large/lv_roberta_large-1.0.0/vocab/vectors.cfg'\n",
      "adding 'lv_roberta_large-1.0.0.dist-info/licenses/LICENSE'\n",
      "adding 'lv_roberta_large-1.0.0.dist-info/licenses/LICENSES_SOURCES'\n",
      "adding 'lv_roberta_large-1.0.0.dist-info/METADATA'\n",
      "adding 'lv_roberta_large-1.0.0.dist-info/WHEEL'\n",
      "adding 'lv_roberta_large-1.0.0.dist-info/entry_points.txt'\n",
      "adding 'lv_roberta_large-1.0.0.dist-info/top_level.txt'\n",
      "adding 'lv_roberta_large-1.0.0.dist-info/RECORD'\n",
      "removing build/bdist.linux-x86_64/wheel\n",
      "\u001b[1m* Creating isolated environment: venv+pip...\u001b[0m\n",
      "\u001b[1m* Installing packages in isolated environment:\u001b[0m\n",
      "  - setuptools >= 40.8.0\n",
      "\u001b[1m* Getting build dependencies for sdist...\u001b[0m\n",
      "running egg_info\n",
      "writing lv_roberta_large.egg-info/PKG-INFO\n",
      "writing dependency_links to lv_roberta_large.egg-info/dependency_links.txt\n",
      "writing entry points to lv_roberta_large.egg-info/entry_points.txt\n",
      "writing requirements to lv_roberta_large.egg-info/requires.txt\n",
      "writing top-level names to lv_roberta_large.egg-info/top_level.txt\n",
      "reading manifest file 'lv_roberta_large.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "adding license file 'LICENSE'\n",
      "adding license file 'LICENSES_SOURCES'\n",
      "writing manifest file 'lv_roberta_large.egg-info/SOURCES.txt'\n",
      "\u001b[1m* Building sdist...\u001b[0m\n",
      "running sdist\n",
      "running egg_info\n",
      "writing lv_roberta_large.egg-info/PKG-INFO\n",
      "writing dependency_links to lv_roberta_large.egg-info/dependency_links.txt\n",
      "writing entry points to lv_roberta_large.egg-info/entry_points.txt\n",
      "writing requirements to lv_roberta_large.egg-info/requires.txt\n",
      "writing top-level names to lv_roberta_large.egg-info/top_level.txt\n",
      "reading manifest file 'lv_roberta_large.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "adding license file 'LICENSE'\n",
      "adding license file 'LICENSES_SOURCES'\n",
      "writing manifest file 'lv_roberta_large.egg-info/SOURCES.txt'\n",
      "running check\n",
      "creating lv_roberta_large-1.0.0\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large.egg-info\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/lemmatizer/lookups\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/morphologizer\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/parser\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/senter\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/tagger\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/transformer\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec\n",
      "creating lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying files to lv_roberta_large-1.0.0...\n",
      "copying LICENSE -> lv_roberta_large-1.0.0\n",
      "copying LICENSES_SOURCES -> lv_roberta_large-1.0.0\n",
      "copying MANIFEST.in -> lv_roberta_large-1.0.0\n",
      "copying README.md -> lv_roberta_large-1.0.0\n",
      "copying meta.json -> lv_roberta_large-1.0.0\n",
      "copying setup.py -> lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/__init__.py -> lv_roberta_large-1.0.0/lv_roberta_large\n",
      "copying lv_roberta_large/meta.json -> lv_roberta_large-1.0.0/lv_roberta_large\n",
      "copying lv_roberta_large.egg-info/PKG-INFO -> lv_roberta_large-1.0.0/lv_roberta_large.egg-info\n",
      "copying lv_roberta_large.egg-info/SOURCES.txt -> lv_roberta_large-1.0.0/lv_roberta_large.egg-info\n",
      "copying lv_roberta_large.egg-info/dependency_links.txt -> lv_roberta_large-1.0.0/lv_roberta_large.egg-info\n",
      "copying lv_roberta_large.egg-info/entry_points.txt -> lv_roberta_large-1.0.0/lv_roberta_large.egg-info\n",
      "copying lv_roberta_large.egg-info/not-zip-safe -> lv_roberta_large-1.0.0/lv_roberta_large.egg-info\n",
      "copying lv_roberta_large.egg-info/requires.txt -> lv_roberta_large-1.0.0/lv_roberta_large.egg-info\n",
      "copying lv_roberta_large.egg-info/top_level.txt -> lv_roberta_large-1.0.0/lv_roberta_large.egg-info\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/LICENSE -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/LICENSES_SOURCES -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/README.md -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/config.cfg -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/meta.json -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/tokenizer -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/lemmatizer/lookups/lookups.bin -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/lemmatizer/lookups\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/morphologizer/cfg -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/morphologizer\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/morphologizer/model -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/morphologizer\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/parser/cfg -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/parser\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/parser/model -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/parser\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/parser/moves -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/parser\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/senter/cfg -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/senter\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/senter/model -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/senter\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/tagger/cfg -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/tagger\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/tagger/model -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/tagger\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/transformer/cfg -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/transformer\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/transformer/model -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/transformer\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec/cfg -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec/model -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/trf_tok2vec\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/vocab/key2row -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/vocab/lookups.bin -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/vocab/strings.json -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/vocab/vectors -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying lv_roberta_large/lv_roberta_large-1.0.0/vocab/vectors.cfg -> lv_roberta_large-1.0.0/lv_roberta_large/lv_roberta_large-1.0.0/vocab\n",
      "copying lv_roberta_large.egg-info/SOURCES.txt -> lv_roberta_large-1.0.0/lv_roberta_large.egg-info\n",
      "Writing lv_roberta_large-1.0.0/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'lv_roberta_large-1.0.0' (and everything under it)\n",
      "\u001b[1m\u001b[92mSuccessfully built \u001b[4mlv_roberta_large-1.0.0-py3-none-any.whl\u001b[0m\u001b[1m\u001b[92m and \u001b[4mlv_roberta_large-1.0.0.tar.gz\u001b[0m\u001b[1m\u001b[92m\u001b[0m\n",
      "wheel + sdist are built, dir: packages/lv_roberta_large-1.0.0/dist\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Cell 9： Build wheel + sdist\n",
    "# ===============================\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "package_output_dir = Path(\"./packages/lv_roberta_large-1.0.0\")\n",
    "\n",
    "# Build wheel and sdist\n",
    "subprocess.run(\n",
    "    [\"python\", \"-m\", \"build\", \"--wheel\", \"--sdist\"],\n",
    "    cwd=str(package_output_dir)\n",
    ")\n",
    "\n",
    "print(f\"wheel + sdist are built, dir: {package_output_dir / 'dist'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f47bbe10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./packages/lv_roberta_large-1.0.0/dist/lv_roberta_large-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: spacy-transformers<1.4.0,>=1.3.9 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from lv-roberta-large==1.0.0) (1.3.9)\n",
      "Requirement already satisfied: spacy<4.1.0,>=3.5.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (3.8.7)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (1.26.4)\n",
      "Requirement already satisfied: transformers<4.50.0,>=3.4.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (4.49.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (2.8.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (2.5.1)\n",
      "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (0.9.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (1.1.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (0.17.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (2.11.9)\n",
      "Requirement already satisfied: jinja2 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (2025.8.3)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (1.2.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (0.1.5)\n",
      "Requirement already satisfied: filelock in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (0.34.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (2025.9.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers<4.50.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (2025.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers<4.50.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (1.1.10)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (0.22.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (7.3.1)\n",
      "Requirement already satisfied: wrapt in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (1.17.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (0.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (3.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from jinja2->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv-roberta-large==1.0.0) (3.0.2)\n",
      "lv-roberta-large is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "lv_roberta_large Pipeline components: ['transformer', 'trf_tok2vec', 'tagger', 'morphologizer', 'parser', 'senter', 'lemmatizer']\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 10A: Install with wheel\n",
    "# ============================\n",
    "import subprocess\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Install with wheel\n",
    "subprocess.run([\n",
    "    \"pip\", \n",
    "    \"install\", \n",
    "    \"./packages/lv_roberta_large-1.0.0/dist/lv_roberta_large-1.0.0-py3-none-any.whl\"\n",
    "])\n",
    "\n",
    "# Load model\n",
    "nlp_xlmr = spacy.load(\"lv_roberta_large\")\n",
    "\n",
    "print(\"lv_roberta_large Pipeline components:\", nlp_xlmr.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "337f62d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./packages/lv_roberta_large-1.0.0/dist/lv_roberta_large-1.0.0.tar.gz\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: spacy-transformers<1.4.0,>=1.3.9 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from lv_roberta_large==1.0.0) (1.3.9)\n",
      "Requirement already satisfied: spacy<4.1.0,>=3.5.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (3.8.7)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (1.26.4)\n",
      "Requirement already satisfied: transformers<4.50.0,>=3.4.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (4.49.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (2.8.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (2.5.1)\n",
      "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (0.9.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (1.1.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (0.17.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (2.11.9)\n",
      "Requirement already satisfied: jinja2 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (2025.8.3)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (1.2.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (0.1.5)\n",
      "Requirement already satisfied: filelock in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (0.34.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (2025.9.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers<4.50.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (2025.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers<4.50.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (1.1.10)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (0.22.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (7.3.1)\n",
      "Requirement already satisfied: wrapt in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (1.17.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (0.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (3.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages (from jinja2->spacy<4.1.0,>=3.5.0->spacy-transformers<1.4.0,>=1.3.9->lv_roberta_large==1.0.0) (3.0.2)\n",
      "Building wheels for collected packages: lv_roberta_large\n",
      "  Building wheel for lv_roberta_large (setup.py): started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m  DEPRECATION: Building 'lv_roberta_large' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'lv_roberta_large'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for lv_roberta_large (setup.py): still running...\n",
      "  Building wheel for lv_roberta_large (setup.py): finished with status 'done'\n",
      "  Created wheel for lv_roberta_large: filename=lv_roberta_large-1.0.0-py3-none-any.whl size=1838687633 sha256=9fb1c37e113adf179af407b05ba924cf67139265e8becaa5352da496de7b0488\n",
      "  Stored in directory: /home/jesse/.cache/pip/wheels/b8/64/33/95beaf99c57149fa1545c30d77dbcb9f217550cb7b37f90f62\n",
      "Successfully built lv_roberta_large\n",
      "Installing collected packages: lv_roberta_large\n",
      "  Attempting uninstall: lv_roberta_large\n",
      "    Found existing installation: lv_roberta_large 1.0.0\n",
      "    Uninstalling lv_roberta_large-1.0.0:\n",
      "      Successfully uninstalled lv_roberta_large-1.0.0\n",
      "Successfully installed lv_roberta_large-1.0.0\n",
      "lv_roberta_large Pipeline components: ['transformer', 'trf_tok2vec', 'tagger', 'morphologizer', 'parser', 'senter', 'lemmatizer']\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Cell 10B: Install with 'tar.gz'\n",
    "# ================================\n",
    "import subprocess\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Install with '.tar.gz'\n",
    "subprocess.run([\"pip\", \"install\", \"./packages/lv_roberta_large-1.0.0/dist/lv_roberta_large-1.0.0.tar.gz\"])\n",
    "nlp_xlmr = spacy.load(\"lv_roberta_large\")\n",
    "\n",
    "print(\"lv_roberta_large Pipeline components:\", nlp_xlmr.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "203adc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: \n",
      "['Baltijas', 'jūras', 'nosaukums', 'ir', 'devis', 'nosaukumu', 'baltu', 'valodām', 'un', 'Baltijas', 'valstīm', '.', '\\n', 'Terminu', '\"', 'Baltijas', 'jūra', '\"', '(', 'Mare', 'Balticum', ')', 'pirmoreiz', 'lietoja', 'vācu', 'hronists', 'Brēmenes', 'Ādams', '11', '.', 'gadsimtā', '.']\n",
      "Lemmas: \n",
      "['Baltijas', 'jūra', 'nosaukums', 'būt', 'dot', 'nosaukums', 'balts', 'valoda', 'un', 'Baltijas', 'valsts', '.', '\\n', 'Terminu', '\"', 'Baltijas', 'jūra', '\"', '(', 'Mare', 'Balticum', ')', 'pirmoreiz', 'lietot', 'vāci', 'hronists', 'Brēmenes', 'Ādams', '11', '.', 'gadsimts', '.']\n",
      "POS tags:\n",
      "Baltijas: PROPN (npfsg4)\n",
      "jūras: NOUN (ncfsg4)\n",
      "nosaukums: NOUN (ncmsn1)\n",
      "ir: AUX (vcnipii30an)\n",
      "devis: VERB (vmnpdmsnasnpn)\n",
      "nosaukumu: NOUN (ncmsa1)\n",
      "baltu: NOUN (ncmpg1)\n",
      "valodām: NOUN (ncfpd4)\n",
      "un: CCONJ (cc)\n",
      "Baltijas: PROPN (npfsg4)\n",
      "valstīm: NOUN (ncfpd6)\n",
      ".: PUNCT (zs)\n",
      "\n",
      ": PUNCT (r0n)\n",
      "Terminu: NOUN (ncmsa1)\n",
      "\": PUNCT (zq)\n",
      "Baltijas: PROPN (npfsg4)\n",
      "jūra: NOUN (ncfsn4)\n",
      "\": PUNCT (zq)\n",
      "(: PUNCT (zb)\n",
      "Mare: X (xf)\n",
      "Balticum: X (xf)\n",
      "): PUNCT (zb)\n",
      "pirmoreiz: ADV (r0n)\n",
      "lietoja: VERB (vmnist230an)\n",
      "vācu: NOUN (ncmdg1)\n",
      "hronists: NOUN (ncmsn1)\n",
      "Brēmenes: PROPN (npfsg5)\n",
      "Ādams: PROPN (npmsn1)\n",
      "11: ADJ (xo)\n",
      ".: ADJ (xo)\n",
      "gadsimtā: NOUN (ncmsl1)\n",
      ".: PUNCT (zs)\n",
      "Morphological features:\n",
      "Baltijas: Case=Gen|Gender=Fem|Number=Sing\n",
      "jūras: Case=Gen|Gender=Fem|Number=Sing\n",
      "nosaukums: Case=Nom|Gender=Masc|Number=Sing\n",
      "ir: Evident=Fh|Mood=Ind|Person=3|Polarity=Pos|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      "devis: Aspect=Perf|Case=Nom|Definite=Ind|Degree=Pos|Gender=Masc|Number=Sing|Polarity=Pos|Tense=Past|VerbForm=Part|Voice=Act\n",
      "nosaukumu: Case=Acc|Gender=Masc|Number=Sing\n",
      "baltu: Case=Gen|Gender=Masc|Number=Plur\n",
      "valodām: Case=Dat|Gender=Fem|Number=Plur\n",
      "un: \n",
      "Baltijas: Case=Gen|Gender=Fem|Number=Sing\n",
      "valstīm: Case=Dat|Gender=Fem|Number=Plur\n",
      ".: \n",
      "\n",
      ": \n",
      "Terminu: Case=Acc|Gender=Masc|Number=Sing\n",
      "\": \n",
      "Baltijas: Case=Gen|Gender=Fem|Number=Sing\n",
      "jūra: Case=Nom|Gender=Fem|Number=Sing\n",
      "\": \n",
      "(: \n",
      "Mare: Foreign=Yes\n",
      "Balticum: Foreign=Yes\n",
      "): \n",
      "pirmoreiz: \n",
      "lietoja: Evident=Fh|Mood=Ind|Person=3|Polarity=Pos|Tense=Past|VerbForm=Fin|Voice=Act\n",
      "vācu: Case=Gen|Gender=Masc|Number=Ptan\n",
      "hronists: Case=Nom|Gender=Masc|Number=Sing\n",
      "Brēmenes: Case=Gen|Gender=Fem|Number=Sing\n",
      "Ādams: Case=Nom|Gender=Masc|Number=Sing\n",
      "11: NumType=Ord\n",
      ".: NumType=Ord\n",
      "gadsimtā: Case=Loc|Gender=Masc|Number=Sing\n",
      ".: \n",
      "Dependency parsing:\n",
      "Baltijas <--nmod-- jūras\n",
      "jūras <--nmod-- nosaukums\n",
      "nosaukums <--nsubj-- devis\n",
      "ir <--aux-- devis\n",
      "devis <--ROOT-- devis\n",
      "nosaukumu <--obj-- devis\n",
      "baltu <--nmod-- valodām\n",
      "valodām <--iobj-- devis\n",
      "un <--cc-- valstīm\n",
      "Baltijas <--nmod-- valstīm\n",
      "valstīm <--conj-- valodām\n",
      ". <--punct-- devis\n",
      "\n",
      " <--ROOT-- \n",
      "\n",
      "Terminu <--nmod-- jūra\n",
      "\" <--punct-- jūra\n",
      "Baltijas <--nmod-- jūra\n",
      "jūra <--obj-- lietoja\n",
      "\" <--punct-- jūra\n",
      "( <--punct-- Mare\n",
      "Mare <--parataxis-- jūra\n",
      "Balticum <--flat:name-- Mare\n",
      ") <--punct-- Mare\n",
      "pirmoreiz <--advmod-- lietoja\n",
      "lietoja <--ROOT-- lietoja\n",
      "vācu <--nmod-- hronists\n",
      "hronists <--nmod-- Ādams\n",
      "Brēmenes <--nmod-- Ādams\n",
      "Ādams <--nsubj-- lietoja\n",
      "11 <--amod-- gadsimtā\n",
      ". <--amod-- gadsimtā\n",
      "gadsimtā <--obl-- lietoja\n",
      ". <--punct-- lietoja\n",
      "Sentences:\n",
      "Baltijas jūras nosaukums ir devis nosaukumu baltu valodām un Baltijas valstīm.\n",
      "\n",
      "\n",
      "Terminu \"Baltijas jūra\" (Mare Balticum) pirmoreiz lietoja vācu hronists Brēmenes Ādams 11. gadsimtā.\n",
      "Pipeline components: \n",
      "['transformer', 'trf_tok2vec', 'tagger', 'morphologizer', 'parser', 'senter', 'lemmatizer']\n",
      "Token vectors shape / Token: (32, 1024)\n"
     ]
    }
   ],
   "source": [
    "# ==================\n",
    "# Cell 11A: Demo Testing\n",
    "# ==================\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "# Load the pipeline\n",
    "nlp = spacy.load(\"lv_roberta_large\")\n",
    "\n",
    "# Example text\n",
    "text = \"\"\"Baltijas jūras nosaukums ir devis nosaukumu baltu valodām un Baltijas valstīm.\n",
    "Terminu \"Baltijas jūra\" (Mare Balticum) pirmoreiz lietoja vācu hronists Brēmenes Ādams 11. gadsimtā.\"\"\"\n",
    "\n",
    "# Process text\n",
    "doc = nlp(text)\n",
    "\n",
    "# ---------------\n",
    "# Tokenization \n",
    "# ---------------\n",
    "print(\"Tokens: \")\n",
    "print([token.text for token in doc])\n",
    "\n",
    "# ---------------\n",
    "# Lemmatization \n",
    "# ---------------\n",
    "print(\"Lemmas: \")\n",
    "print([token.lemma_ for token in doc])\n",
    "\n",
    "# ------------------------\n",
    "# Part-of-Speech Tagging \n",
    "# ------------------------\n",
    "print(\"POS tags:\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text}: {token.pos_} ({token.tag_})\")\n",
    "\n",
    "# ------------------------\n",
    "# Morphological Features\n",
    "# ------------------------\n",
    "print(\"Morphological features:\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text}: {token.morph}\")\n",
    "\n",
    "# ------------------------\n",
    "# Dependency Parsing \n",
    "# ------------------------\n",
    "print(\"Dependency parsing:\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text} <--{token.dep_}-- {token.head.text}\")\n",
    "\n",
    "# ------------------------\n",
    "# Sentence Segmentation \n",
    "# ------------------------\n",
    "print(\"Sentences:\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n",
    "\n",
    "# ------------------------\n",
    "# Print pipeline components\n",
    "# ------------------------\n",
    "print(\"Pipeline components: \")\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "# Tok2Vec\n",
    "vectors = np.vstack([token.vector for token in doc])\n",
    "print(\"Token vectors shape / Token:\", vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8642c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Dependency</th>\n",
       "      <th>Head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rīga</td>\n",
       "      <td>Rīga</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>galvaspilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ir</td>\n",
       "      <td>būt</td>\n",
       "      <td>AUX</td>\n",
       "      <td>cop</td>\n",
       "      <td>galvaspilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Latvijas</td>\n",
       "      <td>Latvijas</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>galvaspilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>galvaspilsēta</td>\n",
       "      <td>galvaspilsēta</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>galvaspilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>un</td>\n",
       "      <td>un</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>cc</td>\n",
       "      <td>viens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>viens</td>\n",
       "      <td>viens</td>\n",
       "      <td>NUM</td>\n",
       "      <td>conj</td>\n",
       "      <td>galvaspilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>centriem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>galvenajiem</td>\n",
       "      <td>galvenais</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>centriem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rūpniecības</td>\n",
       "      <td>rūpniecība</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>centriem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>darījumu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>darījumu</td>\n",
       "      <td>darījums</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>conj</td>\n",
       "      <td>rūpniecības</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>kultūras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kultūras</td>\n",
       "      <td>kultūra</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>conj</td>\n",
       "      <td>rūpniecības</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>sporta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sporta</td>\n",
       "      <td>sports</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>conj</td>\n",
       "      <td>rūpniecības</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>un</td>\n",
       "      <td>un</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>cc</td>\n",
       "      <td>finanšu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>finanšu</td>\n",
       "      <td>finanses</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>conj</td>\n",
       "      <td>rūpniecības</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>centriem</td>\n",
       "      <td>centrs</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>viens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Baltijas</td>\n",
       "      <td>Baltijas</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>valstīs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>valstīs</td>\n",
       "      <td>valsts</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>centriem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>pilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>kā</td>\n",
       "      <td>kas</td>\n",
       "      <td>PART</td>\n",
       "      <td>cc</td>\n",
       "      <td>pilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>arī</td>\n",
       "      <td>arī</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>fixed</td>\n",
       "      <td>kā</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nozīmīga</td>\n",
       "      <td>nozīmīgs</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>pilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ostas</td>\n",
       "      <td>osta</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>pilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pilsēta</td>\n",
       "      <td>pilsēta</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>conj</td>\n",
       "      <td>galvaspilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>galvaspilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Ar</td>\n",
       "      <td>Ar</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>iedzīvotājiem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>605</td>\n",
       "      <td>605</td>\n",
       "      <td>NUM</td>\n",
       "      <td>nummod</td>\n",
       "      <td>iedzīvotājiem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>273</td>\n",
       "      <td>273</td>\n",
       "      <td>NUM</td>\n",
       "      <td>nummod</td>\n",
       "      <td>iedzīvotājiem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>iedzīvotājiem</td>\n",
       "      <td>iedzīvotājs</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>iobj</td>\n",
       "      <td>vieta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(</td>\n",
       "      <td>(</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>dati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>gada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>gada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>gada</td>\n",
       "      <td>gads</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>dati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>dati</td>\n",
       "      <td>dati</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>parataxis</td>\n",
       "      <td>iedzīvotājiem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>)</td>\n",
       "      <td>)</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>dati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tā</td>\n",
       "      <td>tā</td>\n",
       "      <td>DET</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>vieta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ir</td>\n",
       "      <td>būt</td>\n",
       "      <td>AUX</td>\n",
       "      <td>cop</td>\n",
       "      <td>vieta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>lielākā</td>\n",
       "      <td>liels</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>vieta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>apdzīvotā</td>\n",
       "      <td>apdzīvot</td>\n",
       "      <td>VERB</td>\n",
       "      <td>amod</td>\n",
       "      <td>vieta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>vieta</td>\n",
       "      <td>vieta</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>vieta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Latvijā</td>\n",
       "      <td>Latvijā</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>vieta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>vieta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Tās</td>\n",
       "      <td>Tās</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>robežās</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>robežās</td>\n",
       "      <td>robeža</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obl</td>\n",
       "      <td>dzīvo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>dzīvo</td>\n",
       "      <td>dzīvot</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>dzīvo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>aptuveni</td>\n",
       "      <td>aptuveni</td>\n",
       "      <td>ADV</td>\n",
       "      <td>advmod</td>\n",
       "      <td>trešdaļa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>viena</td>\n",
       "      <td>viens</td>\n",
       "      <td>NUM</td>\n",
       "      <td>nummod</td>\n",
       "      <td>trešdaļa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>trešdaļa</td>\n",
       "      <td>trešdaļa</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>dzīvo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>puse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>bet</td>\n",
       "      <td>bet</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>cc</td>\n",
       "      <td>puse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Rīgas</td>\n",
       "      <td>Rīgas</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>aglomerācijā</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>aglomerācijā</td>\n",
       "      <td>aglomerācijā</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>orphan</td>\n",
       "      <td>puse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>—</td>\n",
       "      <td>–</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>puse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>vairāk</td>\n",
       "      <td>daudz</td>\n",
       "      <td>ADV</td>\n",
       "      <td>advmod</td>\n",
       "      <td>puse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>nekā</td>\n",
       "      <td>nekā</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>fixed</td>\n",
       "      <td>vairāk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>puse</td>\n",
       "      <td>puse</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>conj</td>\n",
       "      <td>dzīvo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>visu</td>\n",
       "      <td>viss</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>iedzīvotāju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Latvijas</td>\n",
       "      <td>Latvijas</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>iedzīvotāju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>iedzīvotāju</td>\n",
       "      <td>iedzīvotājs</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>puse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>dzīvo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Pilsētas</td>\n",
       "      <td>Pilsētas</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>teritorijas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>teritorijas</td>\n",
       "      <td>teritorija</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>platība</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>platība</td>\n",
       "      <td>platība</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>km2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>ir</td>\n",
       "      <td>būt</td>\n",
       "      <td>AUX</td>\n",
       "      <td>cop</td>\n",
       "      <td>km2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>307,17</td>\n",
       "      <td>307,17</td>\n",
       "      <td>NUM</td>\n",
       "      <td>nummod</td>\n",
       "      <td>km2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>km2</td>\n",
       "      <td>km2</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>km2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>km2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Rīgas</td>\n",
       "      <td>Rīgas</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>centrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>vēsturiskais</td>\n",
       "      <td>vēsturisks</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>centrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>centrs</td>\n",
       "      <td>centrs</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj:pass</td>\n",
       "      <td>iekļauts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>ir</td>\n",
       "      <td>būt</td>\n",
       "      <td>AUX</td>\n",
       "      <td>aux:pass</td>\n",
       "      <td>iekļauts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>iekļauts</td>\n",
       "      <td>iekļaut</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>iekļauts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>UNESCO</td>\n",
       "      <td>UNESCO</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>mantojuma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Pasaules</td>\n",
       "      <td>Pasaules</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>mantojuma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>kultūras</td>\n",
       "      <td>kultūra</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>mantojuma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>mantojuma</td>\n",
       "      <td>mantojums</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>sarakstā</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>sarakstā</td>\n",
       "      <td>saraksts</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obl</td>\n",
       "      <td>iekļauts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>un</td>\n",
       "      <td>un</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>cc</td>\n",
       "      <td>ievērojams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>ir</td>\n",
       "      <td>būt</td>\n",
       "      <td>AUX</td>\n",
       "      <td>cop</td>\n",
       "      <td>ievērojams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>ievērojams</td>\n",
       "      <td>ievērot</td>\n",
       "      <td>VERB</td>\n",
       "      <td>conj</td>\n",
       "      <td>iekļauts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>ar</td>\n",
       "      <td>ar</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>arhitektūru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>jūgendstila</td>\n",
       "      <td>jūgendstils</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>arhitektūru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>arhitektūru</td>\n",
       "      <td>arhitektūra</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>iobj</td>\n",
       "      <td>ievērojams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>nav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>kurai</td>\n",
       "      <td>kura</td>\n",
       "      <td>DET</td>\n",
       "      <td>obl</td>\n",
       "      <td>nav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>viedokļa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>pēc</td>\n",
       "      <td>pēc</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>viedokļa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>UNESCO</td>\n",
       "      <td>UNESCO</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>viedokļa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>viedokļa</td>\n",
       "      <td>viedoklis</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>discourse</td>\n",
       "      <td>nav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>viedokļa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>nav</td>\n",
       "      <td>būt</td>\n",
       "      <td>VERB</td>\n",
       "      <td>acl</td>\n",
       "      <td>arhitektūru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>līdzīgu</td>\n",
       "      <td>līdzīgs</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>nav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>pasaulē</td>\n",
       "      <td>pasaule</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obl</td>\n",
       "      <td>nav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>iekļauts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Kopš</td>\n",
       "      <td>Kopš</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>dibināšanas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>dibināšanas</td>\n",
       "      <td>dibināšana</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obl</td>\n",
       "      <td>pilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1201</td>\n",
       "      <td>1201</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>gadā</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>gadā</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>gadā</td>\n",
       "      <td>gads</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>dibināšanas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>līdz</td>\n",
       "      <td>līdz</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>dienām</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>mūsu</td>\n",
       "      <td>mēs</td>\n",
       "      <td>PRON</td>\n",
       "      <td>nmod</td>\n",
       "      <td>dienām</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>dienām</td>\n",
       "      <td>diena</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>dibināšanas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Rīga</td>\n",
       "      <td>Rīga</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>pilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>ir</td>\n",
       "      <td>būt</td>\n",
       "      <td>AUX</td>\n",
       "      <td>cop</td>\n",
       "      <td>pilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Baltijas</td>\n",
       "      <td>Baltijas</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>valstu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>valstu</td>\n",
       "      <td>valsts</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>pilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>lielākā</td>\n",
       "      <td>liels</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>pilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>pilsēta</td>\n",
       "      <td>pilsēta</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>pilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>un</td>\n",
       "      <td>un</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>cc</td>\n",
       "      <td>viena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>viena</td>\n",
       "      <td>viens</td>\n",
       "      <td>NUM</td>\n",
       "      <td>conj</td>\n",
       "      <td>pilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>ostām</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>ievērojamākajām</td>\n",
       "      <td>ievērojamākajām</td>\n",
       "      <td>VERB</td>\n",
       "      <td>amod</td>\n",
       "      <td>ostām</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>ostām</td>\n",
       "      <td>osta</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>viena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Baltijas</td>\n",
       "      <td>Baltijas</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>jūras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>jūras</td>\n",
       "      <td>jūra</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>austrumdaļā</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>austrumdaļā</td>\n",
       "      <td>austrumdaļā</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>ostām</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>pilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Politiski</td>\n",
       "      <td>Politiski</td>\n",
       "      <td>ADV</td>\n",
       "      <td>advmod</td>\n",
       "      <td>centrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>un</td>\n",
       "      <td>un</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>cc</td>\n",
       "      <td>administratīvi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>administratīvi</td>\n",
       "      <td>administratīvi</td>\n",
       "      <td>ADV</td>\n",
       "      <td>conj</td>\n",
       "      <td>Politiski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>tā</td>\n",
       "      <td>tā</td>\n",
       "      <td>DET</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>centrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>ilgu</td>\n",
       "      <td>ilgs</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>laiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>laiku</td>\n",
       "      <td>laiks</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obj</td>\n",
       "      <td>centrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>bijusi</td>\n",
       "      <td>būt</td>\n",
       "      <td>AUX</td>\n",
       "      <td>cop</td>\n",
       "      <td>centrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>reģiona</td>\n",
       "      <td>reģions</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>centrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>politiskais</td>\n",
       "      <td>politisks</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>centrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>centrs</td>\n",
       "      <td>centrs</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>centrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>galvaspilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>bet</td>\n",
       "      <td>bet</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>cc</td>\n",
       "      <td>galvaspilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>sākot</td>\n",
       "      <td>sākt</td>\n",
       "      <td>VERB</td>\n",
       "      <td>advcl</td>\n",
       "      <td>galvaspilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>ar</td>\n",
       "      <td>ar</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>gadsimtu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>gadsimtu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>gadsimtu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>gadsimtu</td>\n",
       "      <td>gadsimts</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>iobj</td>\n",
       "      <td>sākot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>—</td>\n",
       "      <td>–</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>galvaspilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Latvijas</td>\n",
       "      <td>Latvijas</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>Republikas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Republikas</td>\n",
       "      <td>Republikas</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>galvaspilsēta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>galvaspilsēta</td>\n",
       "      <td>galvaspilsēta</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>conj</td>\n",
       "      <td>centrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>centrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Text            Lemma    POS  Dependency            Head\n",
       "0               Rīga             Rīga  PROPN       nsubj   galvaspilsēta\n",
       "1                 ir              būt    AUX         cop   galvaspilsēta\n",
       "2           Latvijas         Latvijas  PROPN        nmod   galvaspilsēta\n",
       "3      galvaspilsēta    galvaspilsēta   NOUN        ROOT   galvaspilsēta\n",
       "4                 un               un  CCONJ          cc           viens\n",
       "5              viens            viens    NUM        conj   galvaspilsēta\n",
       "6                 no               no    ADP        case        centriem\n",
       "7        galvenajiem        galvenais    ADJ        amod        centriem\n",
       "8        rūpniecības       rūpniecība   NOUN        nmod        centriem\n",
       "9                  ,                ,  PUNCT       punct        darījumu\n",
       "10          darījumu         darījums   NOUN        conj     rūpniecības\n",
       "11                 ,                ,  PUNCT       punct        kultūras\n",
       "12          kultūras          kultūra   NOUN        conj     rūpniecības\n",
       "13                 ,                ,  PUNCT       punct          sporta\n",
       "14            sporta           sports   NOUN        conj     rūpniecības\n",
       "15                un               un  CCONJ          cc         finanšu\n",
       "16           finanšu         finanses   NOUN        conj     rūpniecības\n",
       "17          centriem           centrs   NOUN        nmod           viens\n",
       "18          Baltijas         Baltijas  PROPN        nmod         valstīs\n",
       "19           valstīs           valsts   NOUN        nmod        centriem\n",
       "20                 ,                ,  PUNCT       punct         pilsēta\n",
       "21                kā              kas   PART          cc         pilsēta\n",
       "22               arī              arī  CCONJ       fixed              kā\n",
       "23          nozīmīga         nozīmīgs    ADJ        amod         pilsēta\n",
       "24             ostas             osta   NOUN        nmod         pilsēta\n",
       "25           pilsēta          pilsēta   NOUN        conj   galvaspilsēta\n",
       "26                 .                .  PUNCT       punct   galvaspilsēta\n",
       "27                Ar               Ar    ADP        case   iedzīvotājiem\n",
       "28               605              605    NUM      nummod   iedzīvotājiem\n",
       "29               273              273    NUM      nummod   iedzīvotājiem\n",
       "30     iedzīvotājiem      iedzīvotājs   NOUN        iobj           vieta\n",
       "31                 (                (  PUNCT       punct            dati\n",
       "32              2024             2024    ADJ        amod            gada\n",
       "33                 .                .    ADJ        amod            gada\n",
       "34              gada             gads   NOUN        nmod            dati\n",
       "35              dati             dati   NOUN   parataxis   iedzīvotājiem\n",
       "36                 )                )  PUNCT       punct            dati\n",
       "37                tā               tā    DET       nsubj           vieta\n",
       "38                ir              būt    AUX         cop           vieta\n",
       "39           lielākā            liels    ADJ        amod           vieta\n",
       "40         apdzīvotā         apdzīvot   VERB        amod           vieta\n",
       "41             vieta            vieta   NOUN        ROOT           vieta\n",
       "42           Latvijā          Latvijā  PROPN        nmod           vieta\n",
       "43                 .                .  PUNCT       punct           vieta\n",
       "44               Tās              Tās    DET         det         robežās\n",
       "45           robežās           robeža   NOUN         obl           dzīvo\n",
       "46             dzīvo           dzīvot   VERB        ROOT           dzīvo\n",
       "47          aptuveni         aptuveni    ADV      advmod        trešdaļa\n",
       "48             viena            viens    NUM      nummod        trešdaļa\n",
       "49          trešdaļa         trešdaļa   NOUN       nsubj           dzīvo\n",
       "50                 ,                ,  PUNCT       punct            puse\n",
       "51               bet              bet  CCONJ          cc            puse\n",
       "52             Rīgas            Rīgas  PROPN        nmod    aglomerācijā\n",
       "53      aglomerācijā     aglomerācijā   NOUN      orphan            puse\n",
       "54                 —                –  PUNCT       punct            puse\n",
       "55            vairāk            daudz    ADV      advmod            puse\n",
       "56              nekā             nekā  SCONJ       fixed          vairāk\n",
       "57              puse             puse   NOUN        conj           dzīvo\n",
       "58              visu             viss    DET         det     iedzīvotāju\n",
       "59          Latvijas         Latvijas  PROPN        nmod     iedzīvotāju\n",
       "60       iedzīvotāju      iedzīvotājs   NOUN        nmod            puse\n",
       "61                 .                .  PUNCT       punct           dzīvo\n",
       "62          Pilsētas         Pilsētas   NOUN        nmod     teritorijas\n",
       "63       teritorijas       teritorija   NOUN        nmod         platība\n",
       "64           platība          platība   NOUN       nsubj             km2\n",
       "65                ir              būt    AUX         cop             km2\n",
       "66            307,17           307,17    NUM      nummod             km2\n",
       "67               km2              km2   NOUN        ROOT             km2\n",
       "68                 .                .  PUNCT       punct             km2\n",
       "69             Rīgas            Rīgas  PROPN        nmod          centrs\n",
       "70      vēsturiskais       vēsturisks    ADJ        amod          centrs\n",
       "71            centrs           centrs   NOUN  nsubj:pass        iekļauts\n",
       "72                ir              būt    AUX    aux:pass        iekļauts\n",
       "73          iekļauts          iekļaut   VERB        ROOT        iekļauts\n",
       "74            UNESCO           UNESCO  PROPN        nmod       mantojuma\n",
       "75          Pasaules         Pasaules   NOUN        nmod       mantojuma\n",
       "76          kultūras          kultūra   NOUN        nmod       mantojuma\n",
       "77         mantojuma        mantojums   NOUN        nmod        sarakstā\n",
       "78          sarakstā         saraksts   NOUN         obl        iekļauts\n",
       "79                un               un  CCONJ          cc      ievērojams\n",
       "80                ir              būt    AUX         cop      ievērojams\n",
       "81        ievērojams          ievērot   VERB        conj        iekļauts\n",
       "82                ar               ar    ADP        case     arhitektūru\n",
       "83       jūgendstila      jūgendstils   NOUN        nmod     arhitektūru\n",
       "84       arhitektūru      arhitektūra   NOUN        iobj      ievērojams\n",
       "85                 ,                ,  PUNCT       punct             nav\n",
       "86             kurai             kura    DET         obl             nav\n",
       "87                 ,                ,  PUNCT       punct        viedokļa\n",
       "88               pēc              pēc    ADP        case        viedokļa\n",
       "89            UNESCO           UNESCO  PROPN        nmod        viedokļa\n",
       "90          viedokļa        viedoklis   NOUN   discourse             nav\n",
       "91                 ,                ,  PUNCT       punct        viedokļa\n",
       "92               nav              būt   VERB         acl     arhitektūru\n",
       "93           līdzīgu          līdzīgs   NOUN       nsubj             nav\n",
       "94           pasaulē          pasaule   NOUN         obl             nav\n",
       "95                 .                .  PUNCT       punct        iekļauts\n",
       "96              Kopš             Kopš    ADP        case     dibināšanas\n",
       "97       dibināšanas       dibināšana   NOUN         obl         pilsēta\n",
       "98              1201             1201    ADJ        amod            gadā\n",
       "99                 .                .    ADJ        amod            gadā\n",
       "100             gadā             gads   NOUN        nmod     dibināšanas\n",
       "101             līdz             līdz    ADP        case          dienām\n",
       "102             mūsu              mēs   PRON        nmod          dienām\n",
       "103           dienām            diena   NOUN        nmod     dibināšanas\n",
       "104             Rīga             Rīga  PROPN       nsubj         pilsēta\n",
       "105               ir              būt    AUX         cop         pilsēta\n",
       "106         Baltijas         Baltijas  PROPN        nmod          valstu\n",
       "107           valstu           valsts   NOUN        nmod         pilsēta\n",
       "108          lielākā            liels    ADJ        amod         pilsēta\n",
       "109          pilsēta          pilsēta   NOUN        ROOT         pilsēta\n",
       "110               un               un  CCONJ          cc           viena\n",
       "111            viena            viens    NUM        conj         pilsēta\n",
       "112               no               no    ADP        case           ostām\n",
       "113  ievērojamākajām  ievērojamākajām   VERB        amod           ostām\n",
       "114            ostām             osta   NOUN        nmod           viena\n",
       "115         Baltijas         Baltijas  PROPN        nmod           jūras\n",
       "116            jūras             jūra   NOUN        nmod     austrumdaļā\n",
       "117      austrumdaļā      austrumdaļā   NOUN        nmod           ostām\n",
       "118                .                .  PUNCT       punct         pilsēta\n",
       "119        Politiski        Politiski    ADV      advmod          centrs\n",
       "120               un               un  CCONJ          cc  administratīvi\n",
       "121   administratīvi   administratīvi    ADV        conj       Politiski\n",
       "122               tā               tā    DET       nsubj          centrs\n",
       "123             ilgu             ilgs    ADJ        amod           laiku\n",
       "124            laiku            laiks   NOUN         obj          centrs\n",
       "125           bijusi              būt    AUX         cop          centrs\n",
       "126          reģiona          reģions   NOUN        nmod          centrs\n",
       "127      politiskais        politisks    ADJ        amod          centrs\n",
       "128           centrs           centrs   NOUN        ROOT          centrs\n",
       "129                ,                ,  PUNCT       punct   galvaspilsēta\n",
       "130              bet              bet  CCONJ          cc   galvaspilsēta\n",
       "131            sākot             sākt   VERB       advcl   galvaspilsēta\n",
       "132               ar               ar    ADP        case        gadsimtu\n",
       "133               20               20    ADJ        amod        gadsimtu\n",
       "134                .                .    ADJ        amod        gadsimtu\n",
       "135         gadsimtu         gadsimts   NOUN        iobj           sākot\n",
       "136                —                –  PUNCT       punct   galvaspilsēta\n",
       "137         Latvijas         Latvijas  PROPN        nmod      Republikas\n",
       "138       Republikas       Republikas   NOUN        nmod   galvaspilsēta\n",
       "139    galvaspilsēta    galvaspilsēta   NOUN        conj          centrs\n",
       "140                .                .  PUNCT       punct          centrs"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence Segmentation results:\n",
      "Sentence 1: Rīga ir Latvijas galvaspilsēta un viens no galvenajiem rūpniecības, darījumu, kultūras, sporta un finanšu centriem Baltijas valstīs, kā arī nozīmīga ostas pilsēta.\n",
      "Sentence 2: Ar 605 273 iedzīvotājiem (2024. gada dati) tā ir lielākā apdzīvotā vieta Latvijā.\n",
      "Sentence 3: Tās robežās dzīvo aptuveni viena trešdaļa, bet Rīgas aglomerācijā — vairāk nekā puse visu Latvijas iedzīvotāju.\n",
      "Sentence 4: Pilsētas teritorijas platība ir 307,17 km2.\n",
      "Sentence 5: Rīgas vēsturiskais centrs ir iekļauts UNESCO Pasaules kultūras mantojuma sarakstā un ir ievērojams ar jūgendstila arhitektūru, kurai, pēc UNESCO viedokļa, nav līdzīgu pasaulē.\n",
      "Sentence 6: Kopš dibināšanas 1201. gadā līdz mūsu dienām Rīga ir Baltijas valstu lielākā pilsēta un viena no ievērojamākajām ostām Baltijas jūras austrumdaļā.\n",
      "Sentence 7: Politiski un administratīvi tā ilgu laiku bijusi reģiona politiskais centrs, bet sākot ar 20. gadsimtu — Latvijas Republikas galvaspilsēta.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# Cell 11B: Testing model, espically Lemma and senter\n",
    "# ===================================================\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load(\"lv_roberta_large\")\n",
    "\n",
    "text = \"\"\"Rīga ir Latvijas galvaspilsēta un viens no galvenajiem rūpniecības, darījumu, kultūras, sporta un finanšu centriem Baltijas valstīs, kā arī nozīmīga ostas pilsēta. Ar 605 273 iedzīvotājiem (2024. gada dati) tā ir lielākā apdzīvotā vieta Latvijā. Tās robežās dzīvo aptuveni viena trešdaļa, bet Rīgas aglomerācijā — vairāk nekā puse visu Latvijas iedzīvotāju. Pilsētas teritorijas platība ir 307,17 km2. Rīgas vēsturiskais centrs ir iekļauts UNESCO Pasaules kultūras mantojuma sarakstā un ir ievērojams ar jūgendstila arhitektūru, kurai, pēc UNESCO viedokļa, nav līdzīgu pasaulē. Kopš dibināšanas 1201. gadā līdz mūsu dienām Rīga ir Baltijas valstu lielākā pilsēta un viena no ievērojamākajām ostām Baltijas jūras austrumdaļā. Politiski un administratīvi tā ilgu laiku bijusi reģiona politiskais centrs, bet sākot ar 20. gadsimtu — Latvijas Republikas galvaspilsēta.\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# Generate Token Table\n",
    "rows = []\n",
    "for sent in doc.sents:\n",
    "    for token in sent:\n",
    "        rows.append({\n",
    "            \"Text\": token.text,\n",
    "            \"Lemma\": token.lemma_,\n",
    "            \"POS\": token.pos_,\n",
    "            \"Dependency\": token.dep_,\n",
    "            \"Head\": token.head.text\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "display(df) \n",
    "\n",
    "# Sentence Segmentation\n",
    "print(\"\\nSentence Segmentation results:\")\n",
    "for i, sent in enumerate(doc.sents, 1):\n",
    "    print(f\"Sentence {i}: {sent.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5ade353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jesse/Projects/myenvs/spacy_lv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2396 gold docs. Example first text:\n",
      "Lai arī viņš tiešām piedzīvoja traģisku galu un viņš savas gleznas nevarēja pārdot, ir jāatzīmē, ka lielāku savas dzīves daļu viņš pavadīja kā mākslas skolotājs un gleznu tirgotājs. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 434kB [00:00, 15.6MB/s]                    \n",
      "2025-09-25 20:39:23 INFO: Downloaded file to /home/jesse/stanza_resources/resources.json\n",
      "2025-09-25 20:39:23 INFO: Downloading default packages for language: lv (Latvian) ...\n",
      "2025-09-25 20:39:23 INFO: File exists: /home/jesse/stanza_resources/lv/default.zip\n",
      "2025-09-25 20:39:24 INFO: Finished downloading models and saved to /home/jesse/stanza_resources\n",
      "2025-09-25 20:39:24 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 434kB [00:00, 7.01MB/s]                    \n",
      "2025-09-25 20:39:24 INFO: Downloaded file to /home/jesse/stanza_resources/resources.json\n",
      "2025-09-25 20:39:25 INFO: Loading these models for language: lv (Latvian):\n",
      "=============================\n",
      "| Processor | Package       |\n",
      "-----------------------------\n",
      "| tokenize  | lvtb          |\n",
      "| pos       | lvtb_nocharlm |\n",
      "| lemma     | lvtb_nocharlm |\n",
      "| depparse  | lvtb_nocharlm |\n",
      "=============================\n",
      "\n",
      "2025-09-25 20:39:25 INFO: Using device: cuda\n",
      "2025-09-25 20:39:25 INFO: Loading: tokenize\n",
      "2025-09-25 20:39:25 INFO: Loading: pos\n",
      "2025-09-25 20:39:26 INFO: Loading: lemma\n",
      "2025-09-25 20:39:26 INFO: Loading: depparse\n",
      "2025-09-25 20:39:26 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Model     POS     Tag   Morph     UAS     LAS  Lemma Acc\n",
      "0  spaCy (lv_roberta_large)  0.9792  0.9267  0.9589  0.9212  0.8883     0.8203\n",
      "1               Stanza (lv)  0.9688  0.8987  0.9449  0.8791  0.8354     0.9539\n",
      "2               UDPipe (lv)  0.9207  0.7960  0.3403  0.0791  0.0660     0.8911\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# Cell 12: Compare with other pipelines\n",
    "# =======================================\n",
    "import spacy\n",
    "import stanza\n",
    "import spacy_udpipe\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training import Example\n",
    "from spacy.scorer import Scorer\n",
    "import pandas as pd\n",
    "      \n",
    "# Load the pipeline\n",
    "nlp_spacy = spacy.load(\"lv_roberta_large\")\n",
    "# ---------- 2. Load gold test set using the model's vocab ----------\n",
    "# IMPORTANT: use nlp_spacy.vocab so gold docs share the same StringStore as predictions\n",
    "doc_bin = DocBin().from_disk(\"test/lv_lvtb-ud-test.spacy\")\n",
    "gold_docs = list(doc_bin.get_docs(nlp_spacy.vocab))\n",
    "\n",
    "# quick sanity check\n",
    "print(f\"Loaded {len(gold_docs)} gold docs. Example first text:\\n{gold_docs[0].text[:200]}\\n\")\n",
    "\n",
    "# ---------- 3. Evaluate spaCy model (using Scorer) ----------\n",
    "# Produce spaCy predictions (these use nlp_spacy.vocab too)\n",
    "pred_docs_spacy = [nlp_spacy(d.text) for d in gold_docs]\n",
    "examples_spacy = [Example(pred, gold) for pred, gold in zip(pred_docs_spacy, gold_docs)]\n",
    "scorer_spacy = Scorer()\n",
    "spacy_scores = scorer_spacy.score(examples_spacy)\n",
    "\n",
    "# ---------- 4. Stanza model: build predicted docs on the SAME vocab and evaluate ----------\n",
    "stanza.download(\"lv\", processors=None)  # will reuse cached; safe to call\n",
    "nlp_stanza = stanza.Pipeline(\"lv\", processors=\"tokenize,pos,lemma,depparse\", use_gpu=True)\n",
    "\n",
    "examples_stanza = []\n",
    "stanza_lemma_preds = []  # keep lemmas for lemma-accuracy calc\n",
    "for gold in gold_docs:\n",
    "    stanza_doc = nlp_stanza(gold.text)\n",
    "    words = [w.text for s in stanza_doc.sentences for w in s.words]\n",
    "    # create predicted Doc using the SAME vocab\n",
    "    pred_doc = spacy.tokens.Doc(nlp_spacy.vocab, words=words)\n",
    "    # copy annotations from stanza into pred_doc\n",
    "    stanza_tokens = [w for s in stanza_doc.sentences for w in s.words]\n",
    "    for token, w in zip(pred_doc, stanza_tokens):\n",
    "        token.pos_ = w.upos\n",
    "        token.tag_ = w.xpos if w.xpos else w.upos\n",
    "        token.lemma_ = w.lemma\n",
    "        token.set_morph(w.feats if w.feats else \"\")\n",
    "        token.dep_ = w.deprel\n",
    "        # head is index-based in stanza; map to pred_doc tokens\n",
    "        token.head = pred_doc[w.head - 1] if w.head > 0 else token\n",
    "    examples_stanza.append(Example(pred_doc, gold))\n",
    "    stanza_lemma_preds.append([t.lemma_ for t in pred_doc])\n",
    "\n",
    "scorer_stanza = Scorer()\n",
    "stanza_scores = scorer_stanza.score(examples_stanza)\n",
    "\n",
    "# ---------- 5. UDPipe model: build predicted docs on the SAME vocab and evaluate ----------\n",
    "\"\"\"\n",
    "The UDPipe model 'latvian-lv0ud-2.5-191206.udpipe' can be downloaded from:\n",
    "https://lindat.mff.cuni.cz/repository/items/41f05304-629f-4313-b9cf-9eeb0a2ca7c6\n",
    "\n",
    "Please download the model and place it under the '/test/' directory if you wish to run evaluations.\n",
    "For better comparison, you may also check for newer versions of the model.\n",
    "\"\"\"\n",
    "\n",
    "udpipe_path = \"test/latvian-lvtb-ud-2.5-191206.udpipe\"\n",
    "nlp_udpipe = spacy_udpipe.load_from_path(lang=\"lv\", path=udpipe_path)\n",
    "\n",
    "examples_udpipe = []\n",
    "udpipe_lemma_preds = []\n",
    "for gold in gold_docs:\n",
    "    udpipe_doc = nlp_udpipe(gold.text)\n",
    "    words = [t.text for t in udpipe_doc]\n",
    "    pred_doc = spacy.tokens.Doc(nlp_spacy.vocab, words=words)\n",
    "    for token, t in zip(pred_doc, udpipe_doc):\n",
    "        token.pos_ = t.pos_\n",
    "        token.tag_ = t.tag_ if t.tag_ else t.pos_\n",
    "        token.lemma_ = t.lemma_\n",
    "        token.set_morph(\"\")  # UDPipe token may not expose FEATS via spacy_udpipe\n",
    "        token.dep_ = t.dep_\n",
    "        token.head = pred_doc[t.head - 1] if t.head > 0 else token\n",
    "    examples_udpipe.append(Example(pred_doc, gold))\n",
    "    udpipe_lemma_preds.append([t.lemma_ for t in pred_doc])\n",
    "\n",
    "scorer_udpipe = Scorer()\n",
    "udpipe_scores = scorer_udpipe.score(examples_udpipe)\n",
    "\n",
    "# ---------- 6. Prepare spaCy lemma preds for comparison ----------\n",
    "spacy_lemma_preds = [[token.lemma_ for token in pred] for pred in pred_docs_spacy]\n",
    "\n",
    "# ---------- 7. Helper functions ----------\n",
    "def get_val(d, key):\n",
    "    \"\"\"Return value for key or NaN if missing.\"\"\"\n",
    "    return d.get(key, float(\"nan\"))\n",
    "\n",
    "def lemma_accuracy(preds, golds):\n",
    "    \"\"\"Token-level lemma accuracy (simple 1:1 token alignment).\"\"\"\n",
    "    total, correct = 0, 0\n",
    "    for p_seq, g_seq in zip(preds, golds):\n",
    "        for p, g in zip(p_seq, g_seq):\n",
    "            total += 1\n",
    "            if p == g:\n",
    "                correct += 1\n",
    "    return correct / total if total > 0 else float(\"nan\")\n",
    "\n",
    "# extract gold lemmas from gold_docs\n",
    "gold_lemmas = [[token.lemma_ for token in doc] for doc in gold_docs]\n",
    "\n",
    "# ---------- 8. Compile results ----------\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": \"spaCy (lv_roberta_large)\",\n",
    "        \"POS\": get_val(spacy_scores, \"pos_acc\"),\n",
    "        \"Tag\": get_val(spacy_scores, \"tag_acc\"),\n",
    "        \"Morph\": get_val(spacy_scores, \"morph_acc\"),\n",
    "        \"UAS\": get_val(spacy_scores, \"dep_uas\"),\n",
    "        \"LAS\": get_val(spacy_scores, \"dep_las\"),\n",
    "        \"Lemma Acc\": lemma_accuracy(spacy_lemma_preds, gold_lemmas)\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Stanza (lv)\",\n",
    "        \"POS\": get_val(stanza_scores, \"pos_acc\"),\n",
    "        \"Tag\": get_val(stanza_scores, \"tag_acc\"),\n",
    "        \"Morph\": get_val(stanza_scores, \"morph_acc\"),\n",
    "        \"UAS\": get_val(stanza_scores, \"dep_uas\"),\n",
    "        \"LAS\": get_val(stanza_scores, \"dep_dlas\") if \"dep_dlas\" in stanza_scores else get_val(stanza_scores, \"dep_las\"),\n",
    "        \"Lemma Acc\": lemma_accuracy(stanza_lemma_preds, gold_lemmas)\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"UDPipe (lv)\",\n",
    "        \"POS\": get_val(udpipe_scores, \"pos_acc\"),\n",
    "        \"Tag\": get_val(udpipe_scores, \"tag_acc\"),\n",
    "        \"Morph\": get_val(udpipe_scores, \"morph_acc\"),\n",
    "        \"UAS\": get_val(udpipe_scores, \"dep_uas\"),\n",
    "        \"LAS\": get_val(udpipe_scores, \"dep_dlas\") if \"dep_dlas\" in udpipe_scores else get_val(udpipe_scores, \"dep_las\"),\n",
    "        \"Lemma Acc\": lemma_accuracy(udpipe_lemma_preds, gold_lemmas)\n",
    "    }\n",
    "])\n",
    "\n",
    "# ---------- 9. Print results ----------\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cb36618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 27 files: 100%|██████████| 27/27 [00:00<00:00, 43640.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2396 gold docs. Example first text:\n",
      "Lai arī viņš tiešām piedzīvoja traģisku galu un viņš savas gleznas nevarēja pārdot, ir jāatzīmē, ka lielāku savas dzīves daļu viņš pavadīja kā mākslas skolotājs un gleznu tirgotājs. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 434kB [00:00, 2.12MB/s]                    \n",
      "2025-09-25 20:43:15 INFO: Downloaded file to /home/jesse/stanza_resources/resources.json\n",
      "2025-09-25 20:43:15 INFO: Downloading default packages for language: lv (Latvian) ...\n",
      "2025-09-25 20:43:15 INFO: File exists: /home/jesse/stanza_resources/lv/default.zip\n",
      "2025-09-25 20:43:16 INFO: Finished downloading models and saved to /home/jesse/stanza_resources\n",
      "2025-09-25 20:43:16 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 434kB [00:00, 7.73MB/s]                    \n",
      "2025-09-25 20:43:16 INFO: Downloaded file to /home/jesse/stanza_resources/resources.json\n",
      "2025-09-25 20:43:17 INFO: Loading these models for language: lv (Latvian):\n",
      "=============================\n",
      "| Processor | Package       |\n",
      "-----------------------------\n",
      "| tokenize  | lvtb          |\n",
      "| pos       | lvtb_nocharlm |\n",
      "| lemma     | lvtb_nocharlm |\n",
      "| depparse  | lvtb_nocharlm |\n",
      "=============================\n",
      "\n",
      "2025-09-25 20:43:17 INFO: Using device: cuda\n",
      "2025-09-25 20:43:17 INFO: Loading: tokenize\n",
      "2025-09-25 20:43:17 INFO: Loading: pos\n",
      "2025-09-25 20:43:18 INFO: Loading: lemma\n",
      "2025-09-25 20:43:18 INFO: Loading: depparse\n",
      "2025-09-25 20:43:18 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Model     POS     Tag   Morph     UAS     LAS  Lemma Acc\n",
      "0  spaCy (lv_roberta_large)  0.9792  0.9267  0.9589  0.9212  0.8883     0.8203\n",
      "1               Stanza (lv)  0.9688  0.8987  0.9449  0.8791  0.8354     0.9539\n",
      "2               UDPipe (lv)  0.9207  0.7960  0.3403  0.0791  0.0660     0.8911\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# Cell 13: Test downloading model from Huggingface hub\n",
    "# =====================================================\n",
    "import spacy\n",
    "import stanza\n",
    "import spacy_udpipe\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training import Example\n",
    "from spacy.scorer import Scorer\n",
    "import pandas as pd\n",
    "from huggingface_hub import snapshot_download\n",
    "      \n",
    "# Load the pipeline\n",
    "model_dir = snapshot_download(repo_id=\"JesseHuang922/lv_roberta_large\", repo_type=\"model\")\n",
    "nlp_spacy = spacy.load(model_dir)\n",
    "# ---------- 2. Load gold test set using the model's vocab ----------\n",
    "# IMPORTANT: use nlp_spacy.vocab so gold docs share the same StringStore as predictions\n",
    "doc_bin = DocBin().from_disk(\"test/lv_lvtb-ud-test.spacy\")\n",
    "gold_docs = list(doc_bin.get_docs(nlp_spacy.vocab))\n",
    "\n",
    "# quick sanity check\n",
    "print(f\"Loaded {len(gold_docs)} gold docs. Example first text:\\n{gold_docs[0].text[:200]}\\n\")\n",
    "\n",
    "# ---------- 3. Evaluate spaCy model (using Scorer) ----------\n",
    "# Produce spaCy predictions (these use nlp_spacy.vocab too)\n",
    "pred_docs_spacy = [nlp_spacy(d.text) for d in gold_docs]\n",
    "examples_spacy = [Example(pred, gold) for pred, gold in zip(pred_docs_spacy, gold_docs)]\n",
    "scorer_spacy = Scorer()\n",
    "spacy_scores = scorer_spacy.score(examples_spacy)\n",
    "\n",
    "# ---------- 4. Stanza model: build predicted docs on the SAME vocab and evaluate ----------\n",
    "stanza.download(\"lv\", processors=None)  # will reuse cached; safe to call\n",
    "nlp_stanza = stanza.Pipeline(\"lv\", processors=\"tokenize,pos,lemma,depparse\", use_gpu=True)\n",
    "\n",
    "examples_stanza = []\n",
    "stanza_lemma_preds = []  # keep lemmas for lemma-accuracy calc\n",
    "for gold in gold_docs:\n",
    "    stanza_doc = nlp_stanza(gold.text)\n",
    "    words = [w.text for s in stanza_doc.sentences for w in s.words]\n",
    "    # create predicted Doc using the SAME vocab\n",
    "    pred_doc = spacy.tokens.Doc(nlp_spacy.vocab, words=words)\n",
    "    # copy annotations from stanza into pred_doc\n",
    "    stanza_tokens = [w for s in stanza_doc.sentences for w in s.words]\n",
    "    for token, w in zip(pred_doc, stanza_tokens):\n",
    "        token.pos_ = w.upos\n",
    "        token.tag_ = w.xpos if w.xpos else w.upos\n",
    "        token.lemma_ = w.lemma\n",
    "        token.set_morph(w.feats if w.feats else \"\")\n",
    "        token.dep_ = w.deprel\n",
    "        # head is index-based in stanza; map to pred_doc tokens\n",
    "        token.head = pred_doc[w.head - 1] if w.head > 0 else token\n",
    "    examples_stanza.append(Example(pred_doc, gold))\n",
    "    stanza_lemma_preds.append([t.lemma_ for t in pred_doc])\n",
    "\n",
    "scorer_stanza = Scorer()\n",
    "stanza_scores = scorer_stanza.score(examples_stanza)\n",
    "\n",
    "# ---------- 5. UDPipe model: build predicted docs on the SAME vocab and evaluate ----------\n",
    "\"\"\"\n",
    "The UDPipe model 'latvian-lv0ud-2.5-191206.udpipe' can be downloaded from:\n",
    "https://lindat.mff.cuni.cz/repository/items/41f05304-629f-4313-b9cf-9eeb0a2ca7c6\n",
    "\n",
    "Please download the model and place it under the '/test/' directory if you wish to run evaluations.\n",
    "For better comparison, you may also check for newer versions of the model.\n",
    "\"\"\"\n",
    "\n",
    "udpipe_path = \"test/latvian-lvtb-ud-2.5-191206.udpipe\"\n",
    "nlp_udpipe = spacy_udpipe.load_from_path(lang=\"lv\", path=udpipe_path)\n",
    "\n",
    "examples_udpipe = []\n",
    "udpipe_lemma_preds = []\n",
    "for gold in gold_docs:\n",
    "    udpipe_doc = nlp_udpipe(gold.text)\n",
    "    words = [t.text for t in udpipe_doc]\n",
    "    pred_doc = spacy.tokens.Doc(nlp_spacy.vocab, words=words)\n",
    "    for token, t in zip(pred_doc, udpipe_doc):\n",
    "        token.pos_ = t.pos_\n",
    "        token.tag_ = t.tag_ if t.tag_ else t.pos_\n",
    "        token.lemma_ = t.lemma_\n",
    "        token.set_morph(\"\")  # UDPipe token may not expose FEATS via spacy_udpipe\n",
    "        token.dep_ = t.dep_\n",
    "        token.head = pred_doc[t.head - 1] if t.head > 0 else token\n",
    "    examples_udpipe.append(Example(pred_doc, gold))\n",
    "    udpipe_lemma_preds.append([t.lemma_ for t in pred_doc])\n",
    "\n",
    "scorer_udpipe = Scorer()\n",
    "udpipe_scores = scorer_udpipe.score(examples_udpipe)\n",
    "\n",
    "# ---------- 6. Prepare spaCy lemma preds for comparison ----------\n",
    "spacy_lemma_preds = [[token.lemma_ for token in pred] for pred in pred_docs_spacy]\n",
    "\n",
    "# ---------- 7. Helper functions ----------\n",
    "def get_val(d, key):\n",
    "    \"\"\"Return value for key or NaN if missing.\"\"\"\n",
    "    return d.get(key, float(\"nan\"))\n",
    "\n",
    "def lemma_accuracy(preds, golds):\n",
    "    \"\"\"Token-level lemma accuracy (simple 1:1 token alignment).\"\"\"\n",
    "    total, correct = 0, 0\n",
    "    for p_seq, g_seq in zip(preds, golds):\n",
    "        for p, g in zip(p_seq, g_seq):\n",
    "            total += 1\n",
    "            if p == g:\n",
    "                correct += 1\n",
    "    return correct / total if total > 0 else float(\"nan\")\n",
    "\n",
    "# extract gold lemmas from gold_docs\n",
    "gold_lemmas = [[token.lemma_ for token in doc] for doc in gold_docs]\n",
    "\n",
    "# ---------- 8. Compile results ----------\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": \"spaCy (lv_roberta_large)\",\n",
    "        \"POS\": get_val(spacy_scores, \"pos_acc\"),\n",
    "        \"Tag\": get_val(spacy_scores, \"tag_acc\"),\n",
    "        \"Morph\": get_val(spacy_scores, \"morph_acc\"),\n",
    "        \"UAS\": get_val(spacy_scores, \"dep_uas\"),\n",
    "        \"LAS\": get_val(spacy_scores, \"dep_las\"),\n",
    "        \"Lemma Acc\": lemma_accuracy(spacy_lemma_preds, gold_lemmas)\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Stanza (lv)\",\n",
    "        \"POS\": get_val(stanza_scores, \"pos_acc\"),\n",
    "        \"Tag\": get_val(stanza_scores, \"tag_acc\"),\n",
    "        \"Morph\": get_val(stanza_scores, \"morph_acc\"),\n",
    "        \"UAS\": get_val(stanza_scores, \"dep_uas\"),\n",
    "        \"LAS\": get_val(stanza_scores, \"dep_dlas\") if \"dep_dlas\" in stanza_scores else get_val(stanza_scores, \"dep_las\"),\n",
    "        \"Lemma Acc\": lemma_accuracy(stanza_lemma_preds, gold_lemmas)\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"UDPipe (lv)\",\n",
    "        \"POS\": get_val(udpipe_scores, \"pos_acc\"),\n",
    "        \"Tag\": get_val(udpipe_scores, \"tag_acc\"),\n",
    "        \"Morph\": get_val(udpipe_scores, \"morph_acc\"),\n",
    "        \"UAS\": get_val(udpipe_scores, \"dep_uas\"),\n",
    "        \"LAS\": get_val(udpipe_scores, \"dep_dlas\") if \"dep_dlas\" in udpipe_scores else get_val(udpipe_scores, \"dep_las\"),\n",
    "        \"Lemma Acc\": lemma_accuracy(udpipe_lemma_preds, gold_lemmas)\n",
    "    }\n",
    "])\n",
    "\n",
    "# ---------- 9. Print results ----------\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy_lv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
